{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/pollard/home/bsmith/Projects/haplo-benchmark/include/StrainFacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "import pyro\n",
    "import scipy as sp\n",
    "\n",
    "import lib.plot\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from lib.pandas_util import idxwhere\n",
    "\n",
    "import sfacts as sf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from lib.project_style import color_palette, major_allele_frequency_bins\n",
    "# from lib.project_data import metagenotype_db_to_xarray\n",
    "# from lib.plot import ordination_plot, mds_ordination, nmds_ordination\n",
    "# import lib.plot\n",
    "# from lib.plot import construct_ordered_pallete\n",
    "# from lib.pandas_util import idxwhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = 102492\n",
    "\n",
    "fit = sf.data.World.load(f'data/zshi.sp-{species_id}.metagenotype.filt-poly05-cvrg25.fit-sfacts44-s200-g5000-seed0.refit-sfacts41-g10000-seed0.world.nc')\n",
    "fit.data['position'] = fit.data.position.astype(int)\n",
    "print(fit.sizes)\n",
    "\n",
    "\n",
    "cull_threshold = 0.05\n",
    "\n",
    "fit_communities = fit.communities.mlift('sel', strain=fit.communities.max(\"sample\") > cull_threshold)\n",
    "print((1 - fit_communities.sum(\"strain\")).max())\n",
    "fit_communities = sf.Communities(fit_communities.data / fit_communities.sum(\"strain\"))\n",
    "fit_genotypes = fit.genotypes.mlift('sel', strain=fit_communities.strain)\n",
    "\n",
    "fit = sf.World.from_combined(fit_communities, fit_genotypes, fit.metagenotypes)\n",
    "print(fit.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_continent_map = dict(\n",
    "    MDG='AF',\n",
    "    TZA='AF',\n",
    "    PER='SA',\n",
    "    USA='NA',\n",
    "    CAN='NA',\n",
    "    GBR='EU',\n",
    "    FRA='EU',\n",
    "    ITA='EU',\n",
    "    ESP='EU',\n",
    "    SWE='EU',\n",
    "    SVK='EU',\n",
    "    HUN='EU',\n",
    "    EST='EU',\n",
    "    AUT='EU',\n",
    "    DEU='EU',\n",
    "    NLD='EU',\n",
    "    DNK='EU',\n",
    "    NOR='EU',\n",
    "    FIN='EU',\n",
    "    RUS='EU',\n",
    "    ISL='EU',\n",
    "    ISR='AS',\n",
    "    KAZ='AS',\n",
    "    MNG='AS',\n",
    "    CHN='AS',\n",
    "    SGP='AS',\n",
    "    BRN='AS',\n",
    "    IDN='AS',\n",
    "    MYS='AS',\n",
    "    BGD='AS',\n",
    "    FJI='OC',\n",
    ")\n",
    "country_order = list(country_to_continent_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_a = pd.read_table('raw/shi2021_s8.tsv', index_col=['NCBI Accession Number'])\n",
    "_b = (\n",
    "    pd.read_table('raw/shi2021_s7.tsv', index_col=['Sample ID', 'Study'])\n",
    "    .assign(\n",
    "        Continent=lambda x: x.Country.map(country_to_continent_map)\n",
    "    )\n",
    ")\n",
    "_c = pd.read_table('raw/shi2021_s13.tsv', index_col=['NCBI Accession Number'])\n",
    "\n",
    "sample_meta = _a.join(_b, on=['Sample ID', 'Study']).join(_c, rsuffix='_')\n",
    "\n",
    "assert (\n",
    "    sample_meta\n",
    "    .dropna(subset=['Country_'])\n",
    "    .assign(\n",
    "        match=lambda x: True\n",
    "        & (x['Sample ID_'] == x['Sample ID'])\n",
    "        & (x.Study_ == x.Study) & (x.Country_ == x.Country)\n",
    "        & (x.Westernized == x['Western Lifestyle'])\n",
    "    )\n",
    "    .match\n",
    "    .all()\n",
    ")\n",
    "assert sample_meta[~(sample_meta.Continent_ == sample_meta.Continent)].dropna(subset=['Continent_']).empty\n",
    "\n",
    "sample_meta = sample_meta.loc[fit.sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta.groupby(['Continent', 'Country', 'Study']).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dist = fit_genotypes.discretized().pdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_thresh = 0.05\n",
    "\n",
    "fit_dedup_clust = pd.Series(\n",
    "    AgglomerativeClustering(\n",
    "        distance_threshold=dedup_thresh, n_clusters=None, affinity='precomputed', linkage='average'\n",
    "    ).fit_predict(fit_dist),\n",
    "    index=fit_dist.columns.astype(int),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_genotypes_dedup = sf.Genotypes(fit_genotypes.to_series().unstack('strain').groupby(fit_dedup_clust, axis='columns').mean().rename(columns=lambda x: int(x)).rename_axis(columns='strain').T.stack().to_xarray())\n",
    "fit_communities_dedup = sf.Communities(fit_communities.to_series().unstack('strain').groupby(fit_dedup_clust, axis='columns').sum().rename(columns=lambda x: int(x)).rename_axis(columns='strain').T.unstack().to_xarray())\n",
    "fit_dedup = sf.World.from_combined(fit_genotypes_dedup, fit_communities_dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fit_genotypes.sizes['strain'], fit_dedup.sizes['strain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_strains = 20\n",
    "min_samples = 5\n",
    "\n",
    "m = sample_meta[\n",
    "    lambda x: True\n",
    "    & (x['Body Site']=='Stool')\n",
    "    & (x['Westernized'] == 'Yes')\n",
    "    & (x['Age Category'] == 'Adult')\n",
    "    & x['Continent'].notna()\n",
    "]\n",
    "d = fit_dedup.sel(sample=m.index)\n",
    "\n",
    "dominant_strain = d.communities.data.argmax(\"strain\").to_series()\n",
    "top_strains = list(dominant_strain.value_counts().sort_values(ascending=False).head(n_top_strains).index)\n",
    "\n",
    "d = (\n",
    "    dominant_strain\n",
    "    .to_frame(name='strain')\n",
    "    .join(sample_meta, how='inner')\n",
    "    .groupby(['Continent', 'Country', 'Study', 'strain'])\n",
    "    .apply(len)\n",
    "    .unstack('strain', fill_value=0)\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    "    .assign(other=lambda x: 1 - x[top_strains].sum(1))\n",
    "    [top_strains + ['other']]\n",
    "    [sample_meta.groupby(['Continent', 'Country', 'Study']).apply(len) > min_samples]\n",
    ")\n",
    "\n",
    "\n",
    "lib.plot.construct_ordered_pallete(top_strains)\n",
    "\n",
    "ax = (\n",
    "    d\n",
    "    .plot\n",
    "    .bar(\n",
    "        width=0.95,\n",
    "        stacked=True,\n",
    "        color=lib.plot.construct_ordered_pallete(top_strains, cm='tab20c', other='whitesmoke'),\n",
    "        figsize=(10, 5)\n",
    "    )\n",
    ")\n",
    "ax.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_thresh = 0.15\n",
    "\n",
    "fit_group_clust = pd.Series(\n",
    "    AgglomerativeClustering(\n",
    "        distance_threshold=group_thresh, n_clusters=None, affinity='precomputed', linkage='average'\n",
    "    ).fit_predict(fit_dist),\n",
    "    index=fit_dist.columns.astype(int),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_genotypes_group = sf.Genotypes(fit_dedup.genotypes.to_series().unstack('strain').groupby(fit_group_clust, axis='columns').mean().rename(columns=lambda x: int(x)).rename_axis(columns='strain').T.stack().to_xarray())\n",
    "fit_communities_group = sf.Communities(fit_dedup.communities.to_series().unstack('strain').groupby(fit_group_clust, axis='columns').sum().rename(columns=lambda x: int(x)).rename_axis(columns='strain').T.unstack().to_xarray())\n",
    "fit_group = sf.World.from_combined(fit_genotypes_group, fit_communities_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_strains = 20\n",
    "min_samples = 5\n",
    "\n",
    "m = sample_meta[\n",
    "    lambda x: True\n",
    "    & (x['Body Site']=='Stool')\n",
    "    & (x['Westernized'] == 'Yes')\n",
    "    & (x['Age Category'] == 'Adult')\n",
    "    & x['Continent'].notna()\n",
    "]\n",
    "d = fit_group.sel(sample=m.index)\n",
    "\n",
    "dominant_strain = d.communities.data.argmax(\"strain\").to_series()\n",
    "top_strains = list(dominant_strain.value_counts().sort_values(ascending=False).head(n_top_strains).index)\n",
    "\n",
    "d = (\n",
    "    dominant_strain\n",
    "    .to_frame(name='strain')\n",
    "    .join(sample_meta, how='inner')\n",
    "    .groupby(['Continent', 'Country', 'Study', 'strain'])\n",
    "    .apply(len)\n",
    "    .unstack('strain', fill_value=0)\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    "    .assign(other=lambda x: 1 - x[top_strains].sum(1))\n",
    "    [top_strains + ['other']]\n",
    "    [sample_meta.groupby(['Continent', 'Country', 'Study']).apply(len) > min_samples]\n",
    ")\n",
    "\n",
    "\n",
    "lib.plot.construct_ordered_pallete(top_strains)\n",
    "\n",
    "ax = (\n",
    "    d\n",
    "    .plot\n",
    "    .bar(\n",
    "        width=0.95,\n",
    "        stacked=True,\n",
    "        color=lib.plot.construct_ordered_pallete(top_strains, cm='tab20c', other='whitesmoke'),\n",
    "        figsize=(10, 5)\n",
    "    )\n",
    ")\n",
    "ax.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def construct_ordered_pallete(x, cm=\"Spectral\", other=\"grey\", weight=None):\n",
    "    if weight is None:\n",
    "        weight = {}\n",
    "    _weight = defaultdict(lambda: 1.0)\n",
    "    _weight.update(weight)\n",
    "    labels = pd.Series(x).unique()\n",
    "    cm = mpl.cm.get_cmap(cm)\n",
    "    colormap = defaultdict(lambda: other)\n",
    "    \n",
    "    countup = 0\n",
    "    for s in labels:\n",
    "        new_countup = countup + _weight[s]\n",
    "        midpoint = (countup + new_countup) / 2\n",
    "        colormap[s] = midpoint\n",
    "        countup = new_countup\n",
    "    for s in colormap:\n",
    "        colormap[s] = cm(colormap[s] / countup)\n",
    "        \n",
    "    return colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_strains = 10000\n",
    "min_samples = 10\n",
    "groupby = ['Westernized', 'Continent', 'Country', 'Study']\n",
    "\n",
    "_meta = sample_meta[\n",
    "    lambda x: True\n",
    "    & (x['Body Site']=='Stool')\n",
    "#     & (x['Westernized'] == 'Yes')\n",
    "    & (x['Age Category'] == 'Adult')\n",
    "    & x['Continent'].notna()\n",
    "]\n",
    "_fit = fit_dedup.sel(sample=_meta.index)\n",
    "\n",
    "d0 = (\n",
    "    _fit\n",
    "    .communities\n",
    "    .data\n",
    "    .to_series()\n",
    "    .unstack()\n",
    "    .idxmax(1)\n",
    "    .to_frame(name='strain')\n",
    "    .assign(dummy=1)\n",
    "    .reset_index()\n",
    "    .set_index(['sample', 'strain'])\n",
    "    .squeeze()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "top_strains = list(d0.sum().sort_values(ascending=False).head(n_top_strains).index)\n",
    "\n",
    "d1 = (\n",
    "    d0[top_strains].assign(other=d0.drop(columns=top_strains).sum(1).astype(int))\n",
    ")\n",
    "\n",
    "d2 = (\n",
    "    d1\n",
    "    [top_strains + ['other']]\n",
    "    .join(_meta[groupby], how='inner')\n",
    ")\n",
    "\n",
    "d3 = (\n",
    "    d2\n",
    "    .groupby(groupby)\n",
    "    .mean()\n",
    "    [d2.groupby(groupby).apply(len) >= min_samples]\n",
    ")\n",
    "\n",
    "# continent_palette = lib.plot.construct_ordered_pallete(_meta.Continent.unique(), cm='Spectral_r')\n",
    "country_palette = construct_ordered_pallete(\n",
    "    country_order,\n",
    "    cm='terrain',\n",
    "    weight=dict(CHN=1)\n",
    ")\n",
    "westernized_palette = construct_ordered_pallete(\n",
    "    ['Yes', 'No'],\n",
    "    cm='binary',\n",
    "    weight=dict(Yes=3)\n",
    ")\n",
    "# westernized_palette = dict(No=(0, 0, 0, 0), Yes=(1, 1, 1, 1))\n",
    "\n",
    "\n",
    "# Plot once without ylabels\n",
    "(fwidth, fheight), dendrogram_ratio, colors_ratio = sf.plot._calculate_clustermap_sizes(\n",
    "    d3.shape[0], d3.shape[1], n_col_colors=0, n_row_colors=2, scaley=0.05, scalex=0.2, cheight=0.2, dheight=2, dwidth=0.7,\n",
    ")\n",
    "clstmap = sns.clustermap(\n",
    "    d3.T + 1e-10,\n",
    "    norm=mpl.colors.PowerNorm(1/3, vmin=0, vmax=1),\n",
    "    xticklabels=0,\n",
    "    yticklabels=0,\n",
    "    metric='cosine',\n",
    "    row_linkage=_fit.sel(strain=top_strains).genotypes.discretized().linkage(),\n",
    "    col_colors=pd.DataFrame(dict(\n",
    "        c=d3.index.to_frame().Country.map(country_palette),\n",
    "#         continent=d3.index.to_frame().Continent.map(continent_palette),\n",
    "        w=d3.index.to_frame().Westernized.map(westernized_palette),\n",
    "    )),\n",
    "    figsize=(fwidth, fheight),\n",
    "    dendrogram_ratio=dendrogram_ratio,\n",
    "    colors_ratio=colors_ratio,\n",
    "    rasterized=True,\n",
    "    tree_kws=dict(lw=1.5),\n",
    ")\n",
    "clstmap.ax_cbar.set_visible(False)\n",
    "clstmap.fig.savefig(f'fig/biogeography_{species_id}.png', dpi=400)\n",
    "\n",
    "# Plot once with xlabels and cbar for manual figure building\n",
    "clstmap = sns.clustermap(\n",
    "    d3.T + 1e-10,\n",
    "    norm=mpl.colors.PowerNorm(1/3, vmin=0, vmax=1),\n",
    "    xticklabels=d3.index.to_frame()[['Country', 'Study']].apply(lambda x: f'{x.Study}-{x.Country}', axis=1).values,\n",
    "    yticklabels=0,\n",
    "    metric='cosine',\n",
    "    row_linkage=_fit.sel(strain=top_strains).genotypes.discretized().linkage(),\n",
    "    col_colors=pd.DataFrame(dict(\n",
    "        c=d3.index.to_frame().Country.map(country_palette),\n",
    "#         continent=d3.index.to_frame().Continent.map(continent_palette),\n",
    "        w=d3.index.to_frame().Westernized.map(westernized_palette),\n",
    "    )),\n",
    "    figsize=(fwidth, fheight),\n",
    "    dendrogram_ratio=dendrogram_ratio,\n",
    "    colors_ratio=colors_ratio,\n",
    "    rasterized=True,\n",
    "    tree_kws=dict(lw=1.5),\n",
    ")\n",
    "clstmap.ax_heatmap.set_xticklabels(clstmap.ax_heatmap.get_xmajorticklabels(), fontsize=14)\n",
    "clstmap.ax_row_dendrogram.set_visible(False)\n",
    "clstmap.ax_col_dendrogram.set_visible(False)\n",
    "clstmap.ax_col_colors.set_visible(False)\n",
    "clstmap.fig.savefig(f'fig/biogeography_{species_id}_figelements.png', dpi=400)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for country in country_palette:\n",
    "    ax.scatter([], [], c=[country_palette[country]], marker='s', label=country)\n",
    "ax.legend(ncol=5)\n",
    "ax.axis('off')\n",
    "fig.savefig(f'fig/biogeography_{species_id}_legend.png', dpi=400)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for westernized in westernized_palette:\n",
    "    ax.scatter([], [], c=[westernized_palette[westernized]], marker='s', s=100, label=westernized)\n",
    "ax.legend(ncol=1)\n",
    "ax.axis('off')\n",
    "fig.savefig(f'fig/biogeography_{species_id}_legend_westernized.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3.index.get_level_values('Study').unique().shape, d3.index.get_level_values('Country').unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fwidth, fheight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_strains = 10000\n",
    "min_samples = 10\n",
    "groupby = ['Westernized', 'Continent', 'Country', 'Study']\n",
    "\n",
    "_meta = sample_meta[\n",
    "    lambda x: True\n",
    "    & (x['Body Site']=='Stool')\n",
    "#     & (x['Westernized'] == 'Yes')\n",
    "    & (x['Age Category'] == 'Adult')\n",
    "    & x['Continent'].notna()\n",
    "]\n",
    "_fit = fit_dedup.sel(sample=_meta.index)\n",
    "\n",
    "d0 = (\n",
    "    _fit\n",
    "    .communities\n",
    "    .data\n",
    "    .to_series()\n",
    "    .unstack()\n",
    "    .idxmax(1)\n",
    "    .to_frame(name='strain')\n",
    "    .assign(dummy=1)\n",
    "    .reset_index()\n",
    "    .set_index(['sample', 'strain'])\n",
    "    .squeeze()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "top_strains = list(d0.sum().sort_values(ascending=False).head(n_top_strains).index)\n",
    "\n",
    "d1 = (\n",
    "    d0[top_strains].assign(other=d0.drop(columns=top_strains).sum(1).astype(int))\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    d0.shape,\n",
    "    d1.join(_meta[groupby]).groupby('Study').apply(len).shape,\n",
    "    (  # How many strains show up in at least 3 continents?\n",
    "        d1\n",
    "        .join(_meta[groupby], how='inner')\n",
    "        .groupby('Continent')\n",
    "        .mean()\n",
    "        .apply(lambda x: x > 0)\n",
    "        .sum()\n",
    "        .apply(lambda x: x >= 3)\n",
    "    #     .mean()\n",
    "        .sum()\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}