{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/pollard/home/bsmith/Projects/haplo-benchmark/include/StrainFacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from lib.pandas_util import idxwhere\n",
    "import sfacts as sf\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "import lib.plot\n",
    "from tqdm import tqdm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi100-mu10-eps10-alpha100-seed3.metagenotype-n100-g500.fit-sfacts36_cpu-s40-g10000-seed2.world\n",
    "# stem = 'data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu10-eps10-alpha100-seed0'\n",
    "# mgen_stem = 'metagenotype-n100-g100'\n",
    "# sim0 = sf.World.load(f'{stem}.world.nc')\n",
    "# mgen = sf.Metagenotypes.load(f'{stem}.{mgen_stem}.nc')\n",
    "\n",
    "# sim = sim0.sel(position=mgen.position, sample=mgen.sample)\n",
    "# fit_stem = 'fit-sfacts36_cpu-s40-g10000-seed0'\n",
    "# fit_init = sf.World.load(f'{stem}.{mgen_stem}.{fit_stem}.world_initial.nc')\n",
    "# fit = sf.World.load(f'{stem}.{mgen_stem}.{fit_stem}.world.nc')\n",
    "\n",
    "benchmarks1 = []\n",
    "for sim_seed, g, n, fit_type, fit_seed in tqdm(list(product(\n",
    "    range(5),\n",
    "    [500, 1000],\n",
    "    [100, 200, 500, 1000],\n",
    "    ['sfacts36_gpu-s40-g10000', 'sfacts36_cpu-s40-g10000', 'sfacts40_cpu-s40-g10000', 'sfinder-s20', 'sfinder-s30'],\n",
    "    range(5),\n",
    "))):\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{sim_seed}\"\n",
    "    eval_path = f\"{sim_prefix}.metagenotype-n{n}-g{g}.fit-{fit_type}-seed{fit_seed}.evaluation.tsv\"\n",
    "    try:\n",
    "        bench = pd.read_table(eval_path, index_col='fit_path')\n",
    "    except FileNotFoundError:\n",
    "#         print(f\"{fit_path} not found\")\n",
    "        continue\n",
    "    \n",
    "    meta_dict = dict(\n",
    "        sim_seed=sim_seed,\n",
    "        g=g,\n",
    "        n=n,\n",
    "        fit_type=fit_type,\n",
    "        fit_seed=fit_seed,\n",
    "        fit_s=fit_s,\n",
    "    )\n",
    "    for key in meta_dict:\n",
    "        bench[key] = meta_dict[key]\n",
    "    benchmarks1.append(bench)\n",
    "benchmarks1 = pd.concat(benchmarks1)\n",
    "print(benchmarks1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{0,1,2,3,4}.metagenotype-n{100,200,500}-g{500,1000}.fit-sfinder-s{20,30}-seed{0,1,2,3,4}.evaluation.tsv\n",
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{0,1,2,3,4}.metagenotype-n{100,200,500}-g{500,1000}.fit-sfacts36_cpu-s40-g10000-seed{0,1,2,3,4}.evaluation.tsv\n",
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{0,1,2,3,4}.metagenotype-n{500,1000}-g{500,1000,5000}.fit-sfacts36_gpu-s40-g10000-seed{0,1,2,3,4}.evaluation.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    benchmarks1\n",
    "#     [lambda x: x.g == 500]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "    .groupby([\n",
    "        'sim_seed',\n",
    "        'g',\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_seed',\n",
    "    ], as_index=False)\n",
    "    .apply(lambda d: d.loc[d.metagenotype_prediction_error.idxmin()])\n",
    "    .sort_values(['fit_type', 'g'])\n",
    ")\n",
    "# d0['fit_type_fit_s'] = d0['fit_type'] + '-s' + d0['fit_s'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts36_cpu-s40-g10000': 'blue',\n",
    "    'sfacts40_cpu-s40-g10000': 'lightblue',\n",
    "    'sfacts36_gpu-s40-g10000': 'purple',\n",
    "    'sfinder-s20': 'green',\n",
    "    'sfinder-s30': 'lightgreen',\n",
    "#     'sfacts1-s40': 'darkgreen',\n",
    "#     'sfacts1_gpu-s20': 'lightgreen',  # 'lightsteelblue',\n",
    "#     'sfacts1_gpu-s40': 'darkgreen',  # 'royalblue',\n",
    "#     'sfacts2-s20': 'khaki',\n",
    "#     'sfacts2-s40': 'darkgoldenrod',\n",
    "#     'sfinder-s20': 'grey',\n",
    "#     'sfinder-s40': 'black',\n",
    "#     'sfacts7-s20': 'lightblue',\n",
    "#     'sfacts7-s40': 'darkblue',\n",
    "}\n",
    "\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "    (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "g_list = [\n",
    "#     50,\n",
    "#     100,\n",
    "#     250,\n",
    "    500,\n",
    "    1000,\n",
    "]\n",
    "n_list = [100, 200, 500, 1000]\n",
    "ncol = len(g_list)\n",
    "nrow = len(metric_list)\n",
    "# nrow = int(np.ceil(len(metrics) / ncol))\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(5 * ncol, 2 * nrow), sharey='row', sharex=True)\n",
    "axs = axs.reshape((nrow, ncol))\n",
    "\n",
    "for (met, scale_kws, ylim_kws), row in zip(metric_list, axs):\n",
    "    row[0].set_yscale(**scale_kws)\n",
    "    row[0].set_ylim(**ylim_kws)\n",
    "    row[0].set_ylabel(met)\n",
    "    for g, ax in zip(g_list, row):\n",
    "        d1 = d0[d0.g == g]\n",
    "        ax.set_title(f'g={g}')\n",
    "        sns.stripplot(\n",
    "            x='n',\n",
    "            y=met,\n",
    "            data=d1,\n",
    "            hue='fit_type',\n",
    "            hue_order=[\n",
    "                'sfacts36_gpu-s40-g10000',\n",
    "                'sfacts36_cpu-s40-g10000',\n",
    "                'sfacts40_cpu-s40-g10000',\n",
    "                'sfinder-s20',\n",
    "                'sfinder-s30',\n",
    "            ],\n",
    "            order=n_list,\n",
    "            s=6,\n",
    "            palette=palette,\n",
    "            ax=ax,\n",
    "            jitter=True,\n",
    "            alpha=0.7,\n",
    "            dodge=True,\n",
    "        )\n",
    "    \n",
    "    \n",
    "for ax in axs.flatten()[1:]:\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        leg.remove()\n",
    "        \n",
    "# for ax in axs[:-1].flatten():\n",
    "#     ax.set_ylim(bottom=1e-4, top=1e0)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "benchmarks1[lambda x: (x.n == 200) & (x.fit_type == 'sfacts36_gpu-s40-g10000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sfacts_simulate-model_simplest_simulation-n{n}-g{{g}}-s{{s}}-{{sim_params}}.metagenotype-n{n}-g{{g}}.fit-{{fit_type}}-s{fit_s}-seed{{seed}}.evaluation.tsv\n",
    "g = 250\n",
    "n_to_s_ratio = 5\n",
    "\n",
    "_benchmarks = []\n",
    "for s, fit_type, sim_seed, fit_seed, fit_s_ratio in tqdm(list(product(\n",
    "    [10, 20, 40, 80, 200, 500],\n",
    "    ['sfinder', 'sfacts40_gpu', 'sfacts40_cpu', 'sfacts40_big'],\n",
    "    range(5),\n",
    "    range(5),\n",
    "    [1, 2],\n",
    "))):\n",
    "    n = s * n_to_s_ratio\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n{n}-g{g}-s{s}-pi40-mu100-eps10-seed{sim_seed}\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    fit_s = s * fit_s_ratio\n",
    "    eval_path = f\"{mgen_prefix}.fit-{fit_type}-s{fit_s}-seed{fit_seed}.evaluation.tsv\"\n",
    "    try:\n",
    "        bench = pd.read_table(eval_path, index_col='fit_path')\n",
    "    except FileNotFoundError:\n",
    "#         print(f\"{fit_path} not found\")\n",
    "        continue\n",
    "    \n",
    "    meta_dict = dict(\n",
    "        sim_seed=sim_seed,\n",
    "        fit_seed=fit_seed,\n",
    "        n=n,\n",
    "        s=s,\n",
    "        fit_s_ratio=fit_s_ratio,\n",
    "        fit_s=fit_s,\n",
    "        fit_type=fit_type,\n",
    "    )\n",
    "    for key in meta_dict:\n",
    "        bench[key] = meta_dict[key]\n",
    "    _benchmarks.append(bench)\n",
    "_benchmarks = pd.concat(_benchmarks)\n",
    "print(_benchmarks.shape)\n",
    "benchmarks2 = _benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    benchmarks2\n",
    "#     [lambda x: x.g == 500]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "    .groupby([\n",
    "        's',\n",
    "        'fit_type',\n",
    "        'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "#         'fit_seed',\n",
    "    ], as_index=False)\n",
    "    .apply(lambda d: d.loc[d.metagenotype_prediction_error.idxmin()])\n",
    ")\n",
    "# d0['fit_type_fit_s'] = d0['fit_type'] + '-s' + d0['fit_s'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts40_cpu': 'purple',\n",
    "    'sfacts40_gpu': 'blue',\n",
    "    'sfacts40_big': 'lightblue',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "    (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "g_list = [\n",
    "#     50,\n",
    "#     100,\n",
    "#     250,\n",
    "    500,\n",
    "    1000,\n",
    "]\n",
    "s_list = [10, 20, 40, 80, 200, 500]\n",
    "fit_s_ratio_list = [1, 2]\n",
    "ncol = len(fit_s_ratio_list)\n",
    "nrow = len(metric_list)\n",
    "# nrow = int(np.ceil(len(metrics) / ncol))\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(5 * ncol, 2 * nrow), sharey='row', sharex=True)\n",
    "axs = axs.reshape((nrow, ncol))\n",
    "\n",
    "for (met, scale_kws, ylim_kws), row in zip(metric_list, axs):\n",
    "    row[0].set_yscale(**scale_kws)\n",
    "    row[0].set_ylim(**ylim_kws)\n",
    "    row[0].set_ylabel(met)\n",
    "    for fit_s_ratio, ax in zip(fit_s_ratio_list, row):\n",
    "        d1 = d0[d0.fit_s_ratio == fit_s_ratio]\n",
    "        ax.set_title(f'fit_s_ratio={fit_s_ratio}')\n",
    "        sns.stripplot(\n",
    "            x='s',\n",
    "            y=met,\n",
    "            data=d1,\n",
    "            hue='fit_type',\n",
    "            hue_order=[\n",
    "                'sfacts40_cpu',\n",
    "                'sfacts40_gpu',\n",
    "                'sfacts40_big',\n",
    "                'sfinder',\n",
    "            ],\n",
    "            order=s_list,\n",
    "            s=6,\n",
    "            palette=palette,\n",
    "            ax=ax,\n",
    "            jitter=True,\n",
    "            alpha=0.7,\n",
    "            dodge=True,\n",
    "        )\n",
    "    \n",
    "    \n",
    "for ax in axs.flatten()[1:]:\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        leg.remove()\n",
    "        \n",
    "# for ax in axs[:-1].flatten():\n",
    "#     ax.set_ylim(bottom=1e-4, top=1e0)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts40_cpu': 'blue',\n",
    "    'sfacts40_gpu': 'purple',\n",
    "    'sfacts40_big': 'lightblue',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .agg(['mean', 'min', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .agg(['mean', 'count'])\n",
    "    ['runtime']\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "for fit_type, d1 in d0[lambda x: x.fit_s_ratio==1].sort_values('n').groupby('fit_type'):\n",
    "    if fit_type == 'sfacts40_big':\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1[('min', 'mean')], c=palette[fit_type], label=fit_type)\n",
    "for fit_type, d1 in d0[lambda x: x.fit_s_ratio==2].sort_values('n').groupby('fit_type'):\n",
    "    if fit_type == 'sfacts40_big':\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1[('min', 'mean')], c=palette[fit_type], linestyle='--')\n",
    "    \n",
    "plt.plot([], [], c='grey', linestyle='-', label='strains = samples * 0.2')\n",
    "plt.plot([], [], c='grey', linestyle='--', label='strains = samples * 0.4')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('runtime (sec)')\n",
    "plt.xlabel('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts40_cpu': 'blue',\n",
    "    'sfacts40_gpu': 'purple',\n",
    "    'sfacts40_big': 'lightblue',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "    .groupby([\n",
    "        's',\n",
    "        'fit_type',\n",
    "        'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .agg(['mean', 'min', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .groupby([\n",
    "        's',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==40) & (x.fit_type.isin(['sfacts40_cpu', 'sfinder']))]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "    (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(metric_list), figsize=(2 * len(metric_list), 4))\n",
    "\n",
    "for (met, scale_kws, ylim_kws), ax in zip(metric_list, axs):\n",
    "    ax.set_ylabel(met)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels(['exact', '2x'])\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "        for fit_type, offset in zip(['sfacts40_cpu', 'sfinder'], [-0.1, 0.1]):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)]\n",
    "            if d3.empty:\n",
    "                continue\n",
    "            ax.scatter([fit_s_ratio + offset], d3[(met, 'min', 'mean')], edgecolor=palette[fit_type], color='white')\n",
    "            ax.scatter([fit_s_ratio + offset], d3[(met, 'mean', 'mean')], color=palette[fit_type])\n",
    "#             ax.vlines([fit_s_ratio + offset], d3[(met, 'min', 'mean')], d3[(met, 'mean', 'mean')], color=palette[fit_type])\n",
    "            ax.vlines([fit_s_ratio + offset], d3[(met, 'mean', 'mean')] - d3[(met, 'std', 'mean')], d3[(met, 'mean', 'mean')] + d3[(met, 'std', 'mean')], color=palette[fit_type])\n",
    "    \n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([40, 200, 1000], [432, 476, 716], label=250, lw=1.5, color='blue')\n",
    "plt.plot([40, 200, 1000], [492, 674, 1740], label=2500, lw=3, color='darkblue')\n",
    "plt.legend(title='g')\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('Maximum GPU Memory Allocated (Mb)')\n",
    "plt.xlabel('nstrains (nsamples=strains * 2.5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sfacts_simulate-model_simplest_simulation-n10000-g1000-s5-pi40-mu100-eps10-seed0.metagenotype-n{100,500,1000,10000}-g{250,500,1000}.fit-sfacts40_gpumem-s{20,40,100,200,400}-seed0.gpumem\n",
    "\n",
    "_benchmarks = []\n",
    "for n, s, g in tqdm(list(product(\n",
    "    [100, 500, 1000, 10000],\n",
    "    [20, 40, 100, 200, 400],\n",
    "    [250, 500, 1000],\n",
    "))):\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n10000-g1000-s5-pi40-mu100-eps10-seed0\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    eval_path = f\"{mgen_prefix}.fit-sfacts40_gpumem-s{s}-seed0.gpumem\"\n",
    "#     print(eval_path)\n",
    "    try:\n",
    "        with open(eval_path) as f:\n",
    "            max_vmem = max([int(line) for i, line in enumerate(f)])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Not found: {eval_path}\")\n",
    "    else:\n",
    "        meta_dict = dict(\n",
    "            n=n, s=s, g=g, max_vmem=max_vmem,\n",
    "        )\n",
    "        _benchmarks.append(meta_dict)\n",
    "_benchmarks = pd.DataFrame(_benchmarks)\n",
    "print(_benchmarks.shape)\n",
    "benchmarks3 = _benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = benchmarks3.assign(n_to_s_ratio=lambda x: x.n / x.s)\n",
    "ordered_s_list = [20, 40, 100, 200, 400]\n",
    "palette = {s: v for s, v in zip(ordered_s_list, mpl.cm.cool(ordered_s_list))}\n",
    "ls_map = {250: ':', 500: '--', 1000: '-'}\n",
    "\n",
    "for (s, g), d1 in d0.sort_values('n').groupby(['s', 'g']):\n",
    "    plt.plot('n', 'max_vmem', ls=ls_map[g], c=palette[s], data=d1, label='__nolegend__')\n",
    "    \n",
    "for s in ordered_s_list:\n",
    "    plt.plot([], [], ls='-', c=palette[s], label=f's={s}')\n",
    "for g in d0.g.unique():\n",
    "    plt.plot([], [], ls=ls_map[g], c='black', label=f'g={g}')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Peak GPU Memory Allocation (Mb)')\n",
    "plt.xlabel('samples')\n",
    "# plt.ylim(4e2, 5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = benchmarks3.assign(n_to_s_ratio=lambda x: x.n / x.s)\n",
    "palette = {\n",
    "    'sfacts40': 'blue',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "for (g, d1), ax in zip(d0.groupby('g'), axs):\n",
    "    ax.set_title(f'g={g}')\n",
    "    for n_to_s_ratio, ls in zip([5, 2.5], ['-', '--']):\n",
    "        d2 = d1[d1.n_to_s_ratio == n_to_s_ratio]\n",
    "        ax.plot('n', 'max_vmem', ls=ls, c=palette['sfacts40'], data=d2, label='__nolegend__')\n",
    "        \n",
    "        \n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "for n_to_s_ratio, ls, ratio in zip([5, 2.5], ['-', '--'], [0.2, 0.4]):\n",
    "    ax.plot([], [], c='black', ls=ls, label=f'strains = samples * {ratio}')\n",
    "plt.legend()\n",
    "    \n",
    "    \n",
    "\n",
    "# for (s, g), d1 in d0.sort_values('n').groupby(['s', 'g']):\n",
    "#     plt.plot('n', 'max_vmem', ls=ls_map[g], c=palette[s], data=d1, label='__nolegend__')\n",
    "    \n",
    "# for s in ordered_s_list:\n",
    "#     plt.plot([], [], ls='-', c=palette[s], label=f's={s}')\n",
    "# for g in d0.g.unique():\n",
    "#     plt.plot([], [], ls=ls_map[g], c='black', label=f'g={g}')\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# plt.ylabel('Peak GPU Memory Allocation (Mb)')\n",
    "# plt.xlabel('samples')\n",
    "# # plt.ylim(4e2, 5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sfacts_simulate-model_simplest_simulation-n1000-g1000-s5-pi40-mu100-eps10-seed0.metagenotype-n{100,200,500}-g{250,500}.fit-{sfacts40,sfinder}_timeit-s{20,40,100,200}-seed0.time\n",
    "\n",
    "import re\n",
    "\n",
    "_benchmarks = []\n",
    "for n, g, fit_type, s in tqdm(list(product(\n",
    "    [100, 200, 500],\n",
    "    [250, 500],\n",
    "    ['sfacts40', 'sfinder'],\n",
    "    [20, 40, 100, 200],\n",
    "))):\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n1000-g1000-s5-pi40-mu100-eps10-seed0\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    eval_path = f\"{mgen_prefix}.fit-{fit_type}_timeit-s{s}-seed0.time\"\n",
    "#     print(eval_path)\n",
    "    try:\n",
    "        with open(eval_path) as f:\n",
    "            d = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(eval_path)\n",
    "        continue\n",
    "    else:\n",
    "        if len(d) == 0:\n",
    "            print(eval_path)\n",
    "            continue\n",
    "        maxrss = int(re.match('.* ([0-9]+)maxresident\\)k', d[0])[1])\n",
    "    meta_dict = dict(\n",
    "        n=n,\n",
    "        g=g,\n",
    "        s=s,\n",
    "        fit_type=fit_type,\n",
    "        maxrss=maxrss,\n",
    "    )\n",
    "    _benchmarks.append(meta_dict)\n",
    "_benchmarks = pd.DataFrame(_benchmarks)\n",
    "print(_benchmarks.shape)\n",
    "benchmarks4 = _benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = benchmarks4.assign(n_to_s_ratio=lambda x: x.n / x.s, maxrss_mb=lambda x: x.maxrss / 1e3)\n",
    "ordered_s_list = [20, 40, 100, 200, 400]\n",
    "\n",
    "ls_map = {250: ':', 500: '--', 1000: '-'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for fit_type, cm in zip(['sfinder', 'sfacts40'], [mpl.cm.summer, mpl.cm.cool]):\n",
    "    palette = {s: v for s, v in zip(ordered_s_list, cm(ordered_s_list))}\n",
    "    for (s, g), d1 in d0[d0.fit_type == fit_type].sort_values('n').groupby(['s', 'g']):\n",
    "        ax.plot('n', 'maxrss_mb', ls=ls_map[g], c=palette[s], data=d1, lw=lw, label='__nolegend__')\n",
    "    for s in d0.s.sort_values().unique():\n",
    "        ax.plot([], [], ls='-', c=palette[s], label=f'{fit_type} (s={s})')\n",
    "\n",
    "ax.legend(ncol=4, bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Peak Main Memory Allocation (Mb)')\n",
    "ax.set_xlabel('samples')\n",
    "ax.set_ylim(5e1, 1e3)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}