{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/pollard/home/bsmith/Projects/haplo-benchmark/include/StrainFacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from lib.pandas_util import idxwhere\n",
    "import sfacts as sf\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "import lib.plot\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import lib.stats\n",
    "\n",
    "def pvalue_to_significance_marker(p):\n",
    "    if p < 1e-3:\n",
    "        return '**'\n",
    "    if p < 0.05:\n",
    "        return '*'\n",
    "    if p >= 0.05:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi100-mu10-eps10-alpha100-seed3.metagenotype-n100-g500.fit-sfacts36_cpu-s40-g10000-seed2.world\n",
    "# stem = 'data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu10-eps10-alpha100-seed0'\n",
    "# mgen_stem = 'metagenotype-n100-g100'\n",
    "# sim0 = sf.World.load(f'{stem}.world.nc')\n",
    "# mgen = sf.Metagenotypes.load(f'{stem}.{mgen_stem}.nc')\n",
    "\n",
    "# sim = sim0.sel(position=mgen.position, sample=mgen.sample)\n",
    "# fit_stem = 'fit-sfacts36_cpu-s40-g10000-seed0'\n",
    "# fit_init = sf.World.load(f'{stem}.{mgen_stem}.{fit_stem}.world_initial.nc')\n",
    "# fit = sf.World.load(f'{stem}.{mgen_stem}.{fit_stem}.world.nc')\n",
    "\n",
    "benchmarks1 = []\n",
    "for sim_seed, g, n, fit_type, fit_seed in tqdm(list(product(\n",
    "    range(5),\n",
    "    [500, 1000],\n",
    "    [100, 200, 500, 1000],\n",
    "    ['sfacts36_gpu-s40-g10000', 'sfacts36_cpu-s40-g10000', 'sfacts40_cpu-s40-g10000', 'sfinder-s20', 'sfinder-s30'],\n",
    "    range(5),\n",
    "))):\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{sim_seed}\"\n",
    "    eval_path = f\"{sim_prefix}.metagenotype-n{n}-g{g}.fit-{fit_type}-seed{fit_seed}.evaluation.tsv\"\n",
    "    try:\n",
    "        bench = pd.read_table(eval_path, index_col='fit_path')\n",
    "    except FileNotFoundError:\n",
    "#         print(f\"{fit_path} not found\")\n",
    "        continue\n",
    "    \n",
    "    meta_dict = dict(\n",
    "        sim_seed=sim_seed,\n",
    "        g=g,\n",
    "        n=n,\n",
    "        fit_type=fit_type,\n",
    "        fit_seed=fit_seed,\n",
    "        fit_s=fit_s,\n",
    "    )\n",
    "    for key in meta_dict:\n",
    "        bench[key] = meta_dict[key]\n",
    "    benchmarks1.append(bench)\n",
    "benchmarks1 = pd.concat(benchmarks1)\n",
    "print(benchmarks1.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{0,1,2,3,4}.metagenotype-n{100,200,500}-g{500,1000}.fit-sfinder-s{20,30}-seed{0,1,2,3,4}.evaluation.tsv\n",
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{0,1,2,3,4}.metagenotype-n{100,200,500}-g{500,1000}.fit-sfacts36_cpu-s40-g10000-seed{0,1,2,3,4}.evaluation.tsv\n",
    "# data/sfacts_simulate-model_ssdd-n1000-g10000-s20-rho10-pi10-mu100-eps10-alpha100-seed{0,1,2,3,4}.metagenotype-n{500,1000}-g{500,1000,5000}.fit-sfacts36_gpu-s40-g10000-seed{0,1,2,3,4}.evaluation.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d0 = (\n",
    "    benchmarks1\n",
    "#     [lambda x: x.g == 500]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "    .groupby([\n",
    "        'sim_seed',\n",
    "        'g',\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_seed',\n",
    "    ], as_index=False)\n",
    "    .apply(lambda d: d.loc[d.metagenotype_prediction_error.idxmin()])\n",
    "    .sort_values(['fit_type', 'g'])\n",
    ")\n",
    "# d0['fit_type_fit_s'] = d0['fit_type'] + '-s' + d0['fit_s'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts36_cpu-s40-g10000': 'blue',\n",
    "    'sfacts40_cpu-s40-g10000': 'lightblue',\n",
    "    'sfacts36_gpu-s40-g10000': 'purple',\n",
    "    'sfinder-s20': 'green',\n",
    "    'sfinder-s30': 'lightgreen',\n",
    "#     'sfacts1-s40': 'darkgreen',\n",
    "#     'sfacts1_gpu-s20': 'lightgreen',  # 'lightsteelblue',\n",
    "#     'sfacts1_gpu-s40': 'darkgreen',  # 'royalblue',\n",
    "#     'sfacts2-s20': 'khaki',\n",
    "#     'sfacts2-s40': 'darkgoldenrod',\n",
    "#     'sfinder-s20': 'grey',\n",
    "#     'sfinder-s40': 'black',\n",
    "#     'sfacts7-s20': 'lightblue',\n",
    "#     'sfacts7-s40': 'darkblue',\n",
    "}\n",
    "\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "    (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "g_list = [\n",
    "#     50,\n",
    "#     100,\n",
    "#     250,\n",
    "    500,\n",
    "    1000,\n",
    "]\n",
    "n_list = [100, 200, 500, 1000]\n",
    "ncol = len(g_list)\n",
    "nrow = len(metric_list)\n",
    "# nrow = int(np.ceil(len(metrics) / ncol))\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(5 * ncol, 2 * nrow), sharey='row', sharex=True)\n",
    "axs = axs.reshape((nrow, ncol))\n",
    "\n",
    "for (met, scale_kws, ylim_kws), row in zip(metric_list, axs):\n",
    "    row[0].set_yscale(**scale_kws)\n",
    "    row[0].set_ylim(**ylim_kws)\n",
    "    row[0].set_ylabel(met)\n",
    "    for g, ax in zip(g_list, row):\n",
    "        d1 = d0[d0.g == g]\n",
    "        ax.set_title(f'g={g}')\n",
    "        sns.stripplot(\n",
    "            x='n',\n",
    "            y=met,\n",
    "            data=d1,\n",
    "            hue='fit_type',\n",
    "            hue_order=[\n",
    "                'sfacts36_gpu-s40-g10000',\n",
    "                'sfacts36_cpu-s40-g10000',\n",
    "                'sfacts40_cpu-s40-g10000',\n",
    "                'sfinder-s20',\n",
    "                'sfinder-s30',\n",
    "            ],\n",
    "            order=n_list,\n",
    "            s=6,\n",
    "            palette=palette,\n",
    "            ax=ax,\n",
    "            jitter=True,\n",
    "            alpha=0.7,\n",
    "            dodge=True,\n",
    "        )\n",
    "    \n",
    "    \n",
    "for ax in axs.flatten()[1:]:\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        leg.remove()\n",
    "        \n",
    "# for ax in axs[:-1].flatten():\n",
    "#     ax.set_ylim(bottom=1e-4, top=1e0)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "benchmarks1[lambda x: (x.n == 200) & (x.fit_type == 'sfacts36_gpu-s40-g10000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"data/sfacts_simulate-model_simplest_simulation-n{n}-g250-s{sim_s}-pi40-mu100-eps10-seed{sim_seed}.metagenotype-n{n}-g250.fit-sfacts41_gpu-s{fit_s}-seed{fit_seed}.evaluation.tsv\"\n",
    "n_to_s_ratio = 5\n",
    "\n",
    "_benchmarks = []\n",
    "for g, s, fit_type, sim_seed, fit_seed, fit_s_ratio in tqdm(list(product(\n",
    "    [250, 1000],\n",
    "    [10, 20, 40, 80, 200, 500],\n",
    "    ['sfinder', 'sfacts44_gpu', 'sfacts44_cpu'],\n",
    "    range(5),\n",
    "    range(5),\n",
    "    [0.5, 0.8, 1, 1.5],\n",
    "))):\n",
    "    n = int(s * n_to_s_ratio)\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n{n}-g{g}-s{s}-pi40-mu100-eps10-seed{sim_seed}\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    fit_s = int(s * fit_s_ratio)\n",
    "    eval_path = f\"{mgen_prefix}.fit-{fit_type}-s{fit_s}-seed{fit_seed}.evaluation.tsv\"\n",
    "    try:\n",
    "        bench = pd.read_table(eval_path, index_col='fit_path')\n",
    "    except FileNotFoundError:\n",
    "#         print(f\"{eval_path} not found\")\n",
    "        continue\n",
    "    \n",
    "    meta_dict = dict(\n",
    "        sim_seed=sim_seed,\n",
    "        fit_seed=fit_seed,\n",
    "        n=n,\n",
    "        g=g,\n",
    "        s=s,\n",
    "        fit_s_ratio=fit_s_ratio,\n",
    "        fit_s=fit_s,\n",
    "        fit_type=fit_type,\n",
    "    )\n",
    "    for key in meta_dict:\n",
    "        bench[key] = meta_dict[key]\n",
    "    _benchmarks.append(bench)\n",
    "    \n",
    "    \n",
    "    \n",
    "for g, s, fit_type, sim_seed, fit_seed, fit_s_ratio in tqdm(list(product(\n",
    "    [250],\n",
    "    [40],\n",
    "    ['mixtureS'],\n",
    "    range(5),\n",
    "    [0],\n",
    "    [1.0],\n",
    "))):\n",
    "    n = int(s * n_to_s_ratio)\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n{n}-g{g}-s{s}-pi40-mu100-eps10-seed{sim_seed}\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    fit_s = np.nan\n",
    "    eval_path = f\"{mgen_prefix}.fit-{fit_type}.evaluation.tsv\"\n",
    "    try:\n",
    "        bench = pd.read_table(eval_path, index_col='fit_path')\n",
    "    except FileNotFoundError:\n",
    "#         print(f\"{eval_path} not found\")\n",
    "        continue\n",
    "    \n",
    "    meta_dict = dict(\n",
    "        sim_seed=sim_seed,\n",
    "        fit_seed=fit_seed,\n",
    "        n=n,\n",
    "        g=g,\n",
    "        s=s,\n",
    "        fit_s_ratio=fit_s_ratio,\n",
    "        fit_s=fit_s,\n",
    "        fit_type=fit_type,\n",
    "    )\n",
    "    for key in meta_dict:\n",
    "        bench[key] = meta_dict[key]\n",
    "    _benchmarks.append(bench)\n",
    "    \n",
    "\n",
    "_benchmarks = pd.concat(_benchmarks)\n",
    "print(_benchmarks.shape)\n",
    "benchmarks2 = _benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"data/sfacts_simulate-model_simplest_simulation-n{n}-g250-s{sim_s}-pi40-mu100-eps10-seed{sim_seed}.metagenotype-n{n}-g250.fit-sfacts41_gpu-s{fit_s}-seed{fit_seed}.evaluation.tsv\"\n",
    "n_to_s_ratio = 5\n",
    "\n",
    "_benchmarks = []\n",
    "for g, s, fit_type, sim_seed, fit_seed, fit_s_ratio in tqdm(list(product(\n",
    "    [250, 1000],\n",
    "    [10, 20, 40, 80, 200, 500],\n",
    "    ['sfinder', 'sfacts44_gpu', 'sfacts44_cpu', 'mixtureS'],\n",
    "    range(5),\n",
    "    range(5),\n",
    "    [0.5, 0.8, 1, 1.5],\n",
    "))):\n",
    "    n = int(s * n_to_s_ratio)\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n{n}-g{g}-s{s}-pi40-mu100-eps10-seed{sim_seed}\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    fit_s = int(s * fit_s_ratio)\n",
    "    eval_path = f\"{mgen_prefix}.fit-{fit_type}-s{fit_s}-seed{fit_seed}.benchmark\"\n",
    "    try:\n",
    "        bench = pd.read_table(eval_path)\n",
    "    except FileNotFoundError:\n",
    "#         print(f\"{eval_path} not found\")\n",
    "        continue\n",
    "    \n",
    "    bench = bench['s'].to_frame(name='runtime_s')\n",
    "    \n",
    "    meta_dict = dict(\n",
    "        sim_seed=sim_seed,\n",
    "        fit_seed=fit_seed,\n",
    "        n=n,\n",
    "        g=g,\n",
    "        s=s,\n",
    "        fit_s_ratio=fit_s_ratio,\n",
    "        fit_s=fit_s,\n",
    "        fit_type=fit_type,\n",
    "    )\n",
    "    for key in meta_dict:\n",
    "        bench[key] = meta_dict[key]\n",
    "    _benchmarks.append(bench)\n",
    "_benchmarks = pd.concat(_benchmarks)\n",
    "print(_benchmarks.shape)\n",
    "benchmarks1 = _benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    benchmarks1\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "#         'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .apply(len)\n",
    "    .unstack('fit_type')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:purple',\n",
    "    'sfacts44_gpu': 'tab:blue',\n",
    "#     'sfacts41_big': 'lightblue',\n",
    "    'sfinder': 'tab:green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks1\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .runtime_s\n",
    "    .agg(['mean', 'max', 'min', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .agg(['mean', 'max', 'median', 'count'])\n",
    "    .reset_index()\n",
    ")\n",
    "# Drop the one sfinder run:\n",
    "d0 = d0.drop(d0[lambda x: (x.n == 1_000) & (x.fit_s_ratio == 1) & (x.fit_type == 'sfinder')].index)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "fit_label_map = {\n",
    "    'sfacts44_gpu': 'StrainFacts (GPU)',\n",
    "    'sfacts44_cpu': 'StrainFacts (CPU)',\n",
    "    'sfinder': 'Strain Finder (CPU)'\n",
    "\n",
    "}\n",
    "\n",
    "for fit_type in ['sfinder', 'sfacts44_cpu', 'sfacts44_gpu']:\n",
    "    d1 = d0[lambda x: x.fit_s_ratio==1].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "    if not fit_type in palette:\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1[('mean', 'mean')], c=palette[fit_type], label=fit_label_map[fit_type])\n",
    "    \n",
    "    \n",
    "for fit_type, d1 in d0[lambda x: x.fit_s_ratio==1.5].sort_values('n').groupby('fit_type'):\n",
    "    if not fit_type in palette:\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1[('mean', 'mean')], c=palette[fit_type], linestyle='--', label='__nolegend__')\n",
    "    \n",
    "plt.plot([], [], c='grey', linestyle='-', label='1x strains')\n",
    "plt.plot([], [], c='grey', linestyle='--', label='1.5x strains')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('mean runtime (sec)')\n",
    "plt.xlabel('samples (N)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0[lambda x: x.fit_type=='sfacts44_cpu'].set_index(['n', 'fit_s_ratio'])[[('max', 'max'), ('mean', 'mean')]] / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0[lambda x: x.fit_type=='sfacts44_gpu'].set_index(['n', 'fit_s_ratio'])[[('max', 'max'), ('mean', 'mean')]] / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0[lambda x: x.fit_type=='sfinder'].set_index(['n', 'fit_s_ratio'])[[('max', 'max'), ('mean', 'mean')]] / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "fit_type_list = ['sfinder', 'sfacts44_cpu', 'sfacts44_gpu']\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:blue',\n",
    "    'sfacts44_gpu': 'tab:purple',\n",
    "#     'sfacts41_big': 'lightblue',\n",
    "    'sfinder': 'tab:green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks1\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "#         'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .runtime_s\n",
    "    .agg(['median'])\n",
    "    .reset_index()\n",
    ")\n",
    "# Drop the one sfinder run:\n",
    "d0 = d0.drop(d0[lambda x: (x.n == 1_000) & (x.fit_s_ratio == 1) & (x.fit_type == 'sfinder')].index)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "fit_label_map = {\n",
    "    'sfacts44_gpu': 'StrainFacts (GPU)',\n",
    "    'sfacts44_cpu': 'StrainFacts (CPU)',\n",
    "    'sfinder': 'Strain Finder (CPU)'\n",
    "\n",
    "}\n",
    "\n",
    "for fit_type in fit_type_list:\n",
    "    d1 = d0[lambda x: x.fit_s_ratio==1].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "    if not fit_type in palette:\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='-', label=fit_label_map[fit_type], lw=2)\n",
    "    \n",
    "    \n",
    "for fit_type in fit_type_list:\n",
    "    d1 = d0[lambda x: x.fit_s_ratio==1.5].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "    if not fit_type in palette:\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='--', label='__nolegend__', lw=2)\n",
    "    \n",
    "    \n",
    "plt.plot([], [], c='grey', linestyle='-', label='1x strains', lw=2)\n",
    "plt.plot([], [], c='grey', linestyle='--', label='1.5x strains', lw=2)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('median runtime (sec)')\n",
    "plt.xlabel('samples (N)')\n",
    "\n",
    "plt.savefig('fig/runtime_profiling.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "fit_type_list = ['sfinder']\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:blue',\n",
    "    'sfacts44_gpu': 'tab:purple',\n",
    "#     'sfacts41_big': 'lightblue',\n",
    "    'sfinder': 'tab:green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks1\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "#         'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .runtime_s\n",
    "    .agg(['median'])\n",
    "    .reset_index()\n",
    ")\n",
    "# Drop the one sfinder run:\n",
    "d0 = d0.drop(d0[lambda x: (x.n == 1_000) & (x.fit_s_ratio == 1) & (x.fit_type == 'sfinder')].index)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "fit_label_map = {\n",
    "    'sfacts44_gpu': 'StrainFacts (GPU)',\n",
    "    'sfacts44_cpu': 'StrainFacts (CPU)',\n",
    "    'sfinder': 'Strain Finder'\n",
    "\n",
    "}\n",
    "\n",
    "for fit_type in fit_type_list:\n",
    "    d1 = d0[lambda x: x.fit_s_ratio==1].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "    if not fit_type in palette:\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='-', label=fit_label_map[fit_type], lw=2)\n",
    "    \n",
    "    \n",
    "# for fit_type in fit_type_list:\n",
    "#     d1 = d0[lambda x: x.fit_s_ratio==1.5].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "#     if not fit_type in palette:\n",
    "#         continue\n",
    "#     plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='--', label='__nolegend__', lw=2)\n",
    "    \n",
    "    \n",
    "# plt.plot([], [], c='grey', linestyle='-', label='1x strains', lw=2)\n",
    "# plt.plot([], [], c='grey', linestyle='--', label='1.5x strains', lw=2)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlim(2e1, 1e4)\n",
    "plt.ylim(1e1, 1e6)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('median runtime (sec)')\n",
    "plt.xlabel('samples (N)')\n",
    "\n",
    "plt.savefig('fig/runtime_profiling_just_sfinder_1x.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "fit_type_list = ['sfinder', 'sfacts44_cpu', ]\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:blue',\n",
    "    'sfacts44_gpu': 'tab:purple',\n",
    "#     'sfacts41_big': 'lightblue',\n",
    "    'sfinder': 'tab:green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks1\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "#         'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .runtime_s\n",
    "    .agg(['median'])\n",
    "    .reset_index()\n",
    ")\n",
    "# Drop the one sfinder run:\n",
    "d0 = d0.drop(d0[lambda x: (x.n == 1_000) & (x.fit_s_ratio == 1) & (x.fit_type == 'sfinder')].index)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "fit_label_map = {\n",
    "    'sfacts44_gpu': 'StrainFacts (GPU)',\n",
    "    'sfacts44_cpu': 'StrainFacts (CPU)',\n",
    "    'sfinder': 'Strain Finder'\n",
    "\n",
    "}\n",
    "\n",
    "for fit_type in fit_type_list:\n",
    "    d1 = d0[lambda x: x.fit_s_ratio==1].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "    if not fit_type in palette:\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='-', label=fit_label_map[fit_type], lw=2)\n",
    "    \n",
    "    \n",
    "# for fit_type in fit_type_list:\n",
    "#     d1 = d0[lambda x: x.fit_s_ratio==1.5].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "#     if not fit_type in palette:\n",
    "#         continue\n",
    "#     plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='--', label='__nolegend__', lw=2)\n",
    "    \n",
    "    \n",
    "# plt.plot([], [], c='grey', linestyle='-', label='1x strains', lw=2)\n",
    "# plt.plot([], [], c='grey', linestyle='--', label='1.5x strains', lw=2)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlim(2e1, 1e4)\n",
    "plt.ylim(1e1, 1e6)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('median runtime (sec)')\n",
    "plt.xlabel('samples (N)')\n",
    "\n",
    "plt.savefig('fig/runtime_profiling_both_1x.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "fit_type_list = ['sfinder', 'sfacts44_cpu', 'sfacts44_gpu']\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:blue',\n",
    "    'sfacts44_gpu': 'tab:purple',\n",
    "#     'sfacts41_big': 'lightblue',\n",
    "    'sfinder': 'tab:green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks1\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "#         'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .runtime_s\n",
    "    .agg(['median'])\n",
    "    .reset_index()\n",
    ")\n",
    "# Drop the one sfinder run:\n",
    "d0 = d0.drop(d0[lambda x: (x.n == 1_000) & (x.fit_s_ratio == 1) & (x.fit_type == 'sfinder')].index)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "fit_label_map = {\n",
    "    'sfacts44_gpu': 'StrainFacts (GPU)',\n",
    "    'sfacts44_cpu': 'StrainFacts (CPU)',\n",
    "    'sfinder': 'Strain Finder'\n",
    "\n",
    "}\n",
    "\n",
    "for fit_type in fit_type_list:\n",
    "    d1 = d0[lambda x: x.fit_s_ratio==1].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "    if not fit_type in palette:\n",
    "        continue\n",
    "    plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='-', label=fit_label_map[fit_type], lw=2)\n",
    "    \n",
    "    \n",
    "# for fit_type in fit_type_list:\n",
    "#     d1 = d0[lambda x: x.fit_s_ratio==1.5].sort_values('n')[lambda x: x.fit_type == fit_type]\n",
    "#     if not fit_type in palette:\n",
    "#         continue\n",
    "#     plt.plot(d1['n'], d1['median'], c=palette[fit_type], linestyle='--', label='__nolegend__', lw=2)\n",
    "    \n",
    "    \n",
    "# plt.plot([], [], c='grey', linestyle='-', label='1x strains', lw=2)\n",
    "# plt.plot([], [], c='grey', linestyle='--', label='1.5x strains', lw=2)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlim(2e1, 1e4)\n",
    "plt.ylim(1e1, 1e6)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('median runtime (sec)')\n",
    "plt.xlabel('samples (N)')\n",
    "\n",
    "plt.savefig('fig/runtime_profiling_all_1x.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    benchmarks1\n",
    "    .assign(runtime_min=lambda x: x.runtime_s / 60)\n",
    "    .groupby([\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .runtime_min\n",
    "    .agg(['median', 'mean', 'max', 'min', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .set_index(['n', 'fit_s_ratio', 'fit_type']).sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    benchmarks2\n",
    "#     [lambda x: x.g == 250]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "    .groupby([\n",
    "        's',\n",
    "        'g',\n",
    "        'fit_type',\n",
    "        'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "#         'fit_seed',\n",
    "    ], as_index=False)\n",
    "#     .apply(lambda d: d.loc[d.metagenotype_prediction_error.idxmin()])\n",
    "    .min()\n",
    ")\n",
    "# d0['fit_type_fit_s'] = d0['fit_type'] + '-s' + d0['fit_s'].astype(str)\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'purple',\n",
    "    'sfacts44_gpu': 'blue',\n",
    "#     'sfacts41_big': 'lightblue',\n",
    "    'sfinder': 'green',\n",
    "#     'sfacts44_big': 'peachpuff',\n",
    "#     'sfacts45_big': 'violet',\n",
    "#     'sfacts46_big': 'lightgreen',\n",
    "\n",
    "}\n",
    "\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "    (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"community_entropy_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "\n",
    "s_list = [10, 20, 40, 80, 200, 500]\n",
    "fit_s_ratio_list = [0.8, 1, 1.5]\n",
    "g = 250\n",
    "ncol = len(fit_s_ratio_list)\n",
    "nrow = len(metric_list)\n",
    "# nrow = int(np.ceil(len(metrics) / ncol))\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(5 * ncol, 2 * nrow), sharey='row', sharex=True)\n",
    "axs = axs.reshape((nrow, ncol))\n",
    "\n",
    "for (met, scale_kws, ylim_kws), row in zip(metric_list, axs):\n",
    "    row[0].set_yscale(**scale_kws)\n",
    "    row[0].set_ylim(**ylim_kws)\n",
    "    row[0].set_ylabel(met)\n",
    "    for fit_s_ratio, ax in zip(fit_s_ratio_list, row):\n",
    "        d1 = d0[(d0.fit_s_ratio == fit_s_ratio) & (d0.g == g)]\n",
    "        ax.set_title(f'fit_s_ratio={fit_s_ratio}')\n",
    "        sns.stripplot(\n",
    "            x='s',\n",
    "            y=met,\n",
    "            data=d1,\n",
    "            hue='fit_type',\n",
    "            hue_order=palette.keys(),\n",
    "            order=s_list,\n",
    "            s=6,\n",
    "            palette=palette,\n",
    "            ax=ax,\n",
    "            jitter=True,\n",
    "            alpha=0.7,\n",
    "            dodge=True,\n",
    "        )\n",
    "    \n",
    "    \n",
    "for ax in axs.flatten()[1:]:\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        leg.remove()\n",
    "        \n",
    "# for ax in axs[:-1].flatten():\n",
    "#     ax.set_ylim(bottom=1e-4, top=1e0)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'purple',\n",
    "#     'sfacts41_gpu': 'blue',\n",
    "#     'sfacts44_big': 'peachpuff',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "#     [lambda x: x.g == 250]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "    .groupby([\n",
    "        's',\n",
    "        'g',\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "        'sim_seed',\n",
    "#         'fit_seed',\n",
    "    ], as_index=False)\n",
    "    .agg(['mean', 'min', 'max', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .groupby([\n",
    "        's',\n",
    "        'g',\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "#         'sim_seed',\n",
    "#         'fit_seed',\n",
    "    ])\n",
    "    .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "g = 250\n",
    "s = 40\n",
    "\n",
    "\n",
    "fit_type_list = list(palette.keys())\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==s) & (x.fit_type.isin(fit_type_list)) & (x.g == g)]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "    (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"community_entropy_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(metric_list), figsize=(2 * len(metric_list), 4))\n",
    "\n",
    "for (met, scale_kws, ylim_kws), ax in zip(metric_list, axs):\n",
    "    ax.set_ylabel(met)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "    ax.set_xticks([0.5, 0.8, 1, 1.5])\n",
    "    ax.set_xticklabels(['0.5x', '0.8x', '1.0x', '1.5x'])\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "        for fit_type, offset in zip(fit_type_list, np.linspace(-0.1, 0.1, num=len(fit_type_list))):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)]\n",
    "#             print(fit_s_ratio, fit_type, d3.shape)\n",
    "            if d3.empty:\n",
    "                continue\n",
    "#             ax.scatter([fit_s_ratio + offset], d3[(met, 'min', 'mean')], edgecolor=palette[fit_type], color='white')\n",
    "            ax.scatter([fit_s_ratio + offset], d3[(met, 'mean', 'mean')], color=palette[fit_type])\n",
    "#             ax.vlines([fit_s_ratio + offset], d3[(met, 'min', 'mean')], d3[(met, 'mean', 'mean')], color=palette[fit_type])\n",
    "            ax.vlines([fit_s_ratio + offset], d3[(met, 'min', 'mean')], d3[(met, 'max', 'mean')], color=palette[fit_type])\n",
    "\n",
    "    \n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'purple',\n",
    "#     'sfacts41_gpu': 'blue',\n",
    "#     'sfacts44_big': 'peachpuff',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "#     [lambda x: x.g == 250]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "    .groupby([\n",
    "        's',\n",
    "        'g',\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "        'sim_seed',\n",
    "#         'fit_seed',\n",
    "    ], as_index=False)\n",
    "    .agg(['mean', 'min', 'max', 'std', 'count', 'median'])\n",
    "    .reset_index()\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ])\n",
    "#     .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "d0['jitter'] = np.random.random(d0.shape[0])\n",
    "\n",
    "g = 250\n",
    "s = 40\n",
    "\n",
    "\n",
    "fit_type_list = list(palette.keys())\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==s) & (x.fit_type.isin(fit_type_list)) & (x.g == g)]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-2, top=1e0)),\n",
    "    (\"community_entropy_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-2, top=1e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(metric_list), figsize=(2 * len(metric_list), 4), sharex=True)\n",
    "\n",
    "for (met, scale_kws, ylim_kws), ax in zip(metric_list, axs):\n",
    "    ax.set_ylabel(met)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "#     ax.set_yscale('symlog', linthresh=1e-5)\n",
    "    ax.set_xticks([0.5, 0.8, 1, 1.5])\n",
    "    ax.set_xticklabels(['0.5x', '0.8x', '1.0x', '1.5x'])\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "        mwu = lib.stats.mannwhitneyu('fit_type', (met, 'min'), data=d2.sort_values('sim_seed'))\n",
    "        print(met, fit_s_ratio, mwu, d2['fit_s_ratio'].values[0] + 0.04)\n",
    "        ax.annotate(\n",
    "            pvalue_to_significance_marker(mwu[1]),\n",
    "            xy=(\n",
    "                d2['fit_s_ratio'].values[0] + 0.04,\n",
    "                0.87\n",
    "            ), ha='center', va='top', fontsize=13)\n",
    "        for fit_type, offset in zip(fit_type_list, np.linspace(-1, 1, num=len(fit_type_list))):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)]\n",
    "#             print(fit_s_ratio, fit_type, d3.shape)\n",
    "            if d3.empty:\n",
    "                continue\n",
    "            ax.scatter(d3['fit_s_ratio'] + d3['jitter'] * 0.07 + offset * 0.1, d3[(met, 'min')], edgecolor='lightgrey', color=palette[fit_type], alpha=0.7)\n",
    "#             ax.vlines(d3['fit_s_ratio'] + d3['jitter'] * 0.07 + offset * 0.1, d3[(met, 'min')], d3[(met, 'median')], color=palette[fit_type], lw=1, alpha=0.7)\n",
    "\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'purple',\n",
    "#     'sfacts41_gpu': 'blue',\n",
    "#     'sfacts44_big': 'peachpuff',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "#     [lambda x: x.g == 250]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "    .groupby([\n",
    "        's',\n",
    "        'g',\n",
    "        'n',\n",
    "        'fit_type',\n",
    "        'fit_s_ratio',\n",
    "        'sim_seed',\n",
    "#         'fit_seed',\n",
    "    ], as_index=False)\n",
    "    .agg(['mean', 'min', 'max', 'std', 'count', 'median'])\n",
    "    .reset_index()\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ])\n",
    "#     .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "# d0['jitter'] = np.random.random(d0.shape[0])\n",
    "\n",
    "g = 250\n",
    "s = 40\n",
    "\n",
    "\n",
    "fit_type_list = list(palette.keys())\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==s) & (x.fit_type.isin(fit_type_list)) & (x.g == g)]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", 'Unifrac Error', dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-2, top=1e0)),\n",
    "    (\"community_entropy_error\", 'Community Entropy Error', dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-2, top=1e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", 'Forward Genotype Error', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", 'Reverse Genotype Error', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, len(metric_list), figsize=(3 * len(metric_list), 4), sharex=True)\n",
    "\n",
    "for (met, axis_label, scale_kws, ylim_kws), ax in zip(metric_list, axs):\n",
    "    ax.set_ylabel(axis_label)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "#     ax.set_yscale('symlog', linthresh=1e-5)\n",
    "    ax.set_xticks([0.5, 0.8, 1, 1.5])\n",
    "    ax.set_xticklabels(['0.5x', '0.8x', '1.0x', '1.5x'])\n",
    "    ax.set_xlabel('strains')\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "        mwu = lib.stats.mannwhitneyu('fit_type', (met, 'min'), data=d2.sort_values('sim_seed'))\n",
    "        print(met, fit_s_ratio, mwu, d2['fit_s_ratio'].values[0] + 0.04)\n",
    "        ax.annotate(\n",
    "            pvalue_to_significance_marker(mwu[1]),\n",
    "            xy=(\n",
    "                d2['fit_s_ratio'].values[0] + 0.04,\n",
    "                0.87\n",
    "            ), ha='center', va='top', fontsize=13)\n",
    "        for fit_type, offset in zip(fit_type_list, np.linspace(-1, 1, num=len(fit_type_list))):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)].sort_values((met, 'min'))\n",
    "            d3['jitter'] = np.linspace(-1, 1, num=d3.shape[0])\n",
    "#             print(fit_s_ratio, fit_type, d3.shape)\n",
    "            if d3.empty:\n",
    "                continue\n",
    "            ax.scatter(d3['fit_s_ratio'] + d3['jitter'] * 0.07 + offset * 0.1, d3[(met, 'min')], edgecolor='lightgrey', color=palette[fit_type], alpha=0.7)\n",
    "            ax.vlines(d3['fit_s_ratio'] + d3['jitter'] * 0.07 + offset * 0.1, d3[(met, 'min')], d3[(met, 'median')], color=palette[fit_type], lw=1, alpha=0.7)\n",
    "\n",
    "    \n",
    "fig.tight_layout(w_pad=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:blue',\n",
    "#     'sfacts41_gpu': 'blue',\n",
    "#     'sfacts44_big': 'peachpuff',\n",
    "    'sfinder': 'tab:green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "#     [lambda x: x.g == 250]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ], as_index=False)\n",
    "#     .agg(['mean', 'min', 'max', 'std', 'count', 'median'])\n",
    "#     .reset_index()\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ])\n",
    "#     .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "d0['jitter'] = np.random.random(d0.shape[0]) * 2 - 1\n",
    "\n",
    "g = 250\n",
    "s = 40\n",
    "\n",
    "\n",
    "fit_type_list = list(palette.keys())\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==s) & (x.fit_type.isin(fit_type_list)) & (x.g == g)]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", 'Unifrac Distance', 'mean distance', dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=2e0)),\n",
    "    (\"braycurtis_trans_error\", \"Pairwise Bray-Curtis\", 'mean absolute error', dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=2e0)),\n",
    "    (\"community_entropy_error\", 'Compositional Entropy', 'mean absolute error', dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=2e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", 'Best Match to True Genotype', 'weighted mean distance', dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=2e0)),\n",
    "    (\"rev_discrete_genotype_error\", 'Best Match to Inferred Genotype', 'weighted mean distance', dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=2e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "ncol = 3\n",
    "nrow = int(np.ceil(len(metric_list) / ncol))\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(3.6 * ncol, 4 * nrow), sharex=True)\n",
    "\n",
    "for (met, title, axis_label, scale_kws, ylim_kws), ax in zip(metric_list, axs.flatten()):\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(axis_label)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "#     ax.set_yscale('symlog', linthresh=1e-5)\n",
    "    ax.set_xticks([0.5, 0.8, 1, 1.5])\n",
    "    ax.set_xticklabels(['0.5x', '0.8x', '1.0x', '1.5x'])\n",
    "#     ax.set_xlim(0.85, 1.65)\n",
    "    ax.set_xlabel('strains')\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "        mwu = lib.stats.wilcoxon('fit_type', met, data=d2.sort_values(['sim_seed', 'fit_seed']))\n",
    "        print(met, fit_s_ratio, mwu, )\n",
    "        ax.annotate(\n",
    "            pvalue_to_significance_marker(mwu[1]),\n",
    "            xy=(\n",
    "                d2['fit_s_ratio'].values[0],\n",
    "                0.87\n",
    "            ), ha='center', va='top', fontsize=13)\n",
    "        for fit_type, offset in zip(fit_type_list, np.linspace(-1, 1, num=len(fit_type_list))):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)]#.sort_values((met, 'min'))\n",
    "            print(d3[met].median())\n",
    "#             print(fit_s_ratio, fit_type, d3.shape)\n",
    "            if d3.empty:\n",
    "                continue\n",
    "            ax.scatter(d3['fit_s_ratio'] + d3['jitter'] * 0.04 + offset * 0.07, d3[met], edgecolor='lightgrey', color=palette[fit_type], alpha=0.7)\n",
    "\n",
    "axs[-1, -1].axis('off')\n",
    "\n",
    "    \n",
    "fig.tight_layout(w_pad=2., h_pad=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:blue',\n",
    "#     'sfacts41_gpu': 'blue',\n",
    "#     'sfacts44_big': 'peachpuff',\n",
    "    'sfinder': 'tab:green',\n",
    "#     'mixtureS': 'tab:cyan'\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "    [lambda x: x.fit_s_ratio.isin([0.8, 1.0, 1.5])]\n",
    "    .assign(xpos=lambda x: x.fit_s_ratio.map({0.8: 0.5, 1.0: 1.0, 1.5: 1.5}))\n",
    "#     [lambda x: x.g == 250]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ], as_index=False)\n",
    "#     .agg(['mean', 'min', 'max', 'std', 'count', 'median'])\n",
    "#     .reset_index()\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ])\n",
    "#     .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "d0['jitter'] = np.random.random(d0.shape[0]) * 2 - 1\n",
    "\n",
    "g = 250\n",
    "s = 40\n",
    "\n",
    "\n",
    "fit_type_list = list(palette.keys())\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==s) & (x.fit_type.isin(fit_type_list)) & (x.g == g)]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", 'Unifrac Distance', 'mean distance', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "    (\"braycurtis_trans_error\", \"Pairwise Bray-Curtis\", 'mean absolute error', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "    (\"community_entropy_error\", 'Compositional Entropy', 'mean absolute error', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", 'Best Match to True Genotype', 'weighted mean distance', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "    (\"rev_discrete_genotype_error\", 'Best Match to Inferred Genotype', 'weighted mean distance', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "ncol = 3\n",
    "nrow = int(np.ceil(len(metric_list) / ncol))\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(3.6 * ncol, 4 * nrow), sharex=True)\n",
    "\n",
    "for panel_letter, (met, title, axis_label, scale_kws, ylim_kws), ax in zip([\"A\", \"B\", \"C\", \"D\", \"E\"], metric_list, axs.flatten()):\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(axis_label)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "#     ax.set_yscale('symlog', linthresh=1e-5)\n",
    "    ax.set_xticks([0.5, 1, 1.5])\n",
    "    ax.set_xticklabels(['0.8x', '1.0x', '1.5x'])\n",
    "#     ax.set_xlim(0.85, 1.65)\n",
    "    ax.set_xlabel('strains')\n",
    "    ax.annotate(panel_letter, xy=(-0.1, 1.05), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "        d3 = d2.drop(idxwhere(d2.fit_type == 'mixtureS'))\n",
    "        mwu = lib.stats.mannwhitneyu('fit_type', met, data=d3.sort_values(['sim_seed', 'fit_seed']))\n",
    "        print(met, fit_s_ratio, mwu, )\n",
    "        ax.annotate(\n",
    "            pvalue_to_significance_marker(mwu[1]),\n",
    "            xy=(\n",
    "                d2['xpos'].values[0],\n",
    "                1.5\n",
    "            ), ha='center', va='top', fontsize=13)\n",
    "        for fit_type, offset in zip(fit_type_list, np.linspace(-1, 1, num=len(fit_type_list))):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)]#.sort_values((met, 'min'))\n",
    "            print(d3[met].median())\n",
    "#             print(fit_s_ratio, fit_type, d3.shape)\n",
    "            if d3.empty:\n",
    "                continue\n",
    "            ax.scatter(d3['xpos'] + d3['jitter'] * 0.04 + offset * 0.07, d3[met], edgecolor='lightgrey', color=palette[fit_type], alpha=0.7)\n",
    "\n",
    "axs[-1, -1].axis('off')\n",
    "\n",
    "    \n",
    "fig.tight_layout(w_pad=2., h_pad=3.)\n",
    "fig.savefig('fig/accuracy_benchmarking.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.0, 1.0))\n",
    "for fit_type, fit_name in [('sfacts44_cpu', 'StrainFacts'), ('sfinder', 'Strain Finder')]:\n",
    "    ax.scatter([], [], edgecolor='lightgrey', color=palette[fit_type], label=fit_name, s=100)\n",
    "ax.legend(loc='upper left')\n",
    "ax.axis('off')\n",
    "fig.savefig('fig/accuracy_benchmarking_legend.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts44_cpu': 'tab:blue',\n",
    "#     'sfacts41_gpu': 'blue',\n",
    "#     'sfacts44_big': 'peachpuff',\n",
    "    'sfinder': 'tab:green',\n",
    "    'mixtureS': 'tab:cyan'\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "    [lambda x: x.fit_s_ratio.isin([0.8, 1.0, 1.5])]\n",
    "    .assign(xpos=lambda x: x.fit_s_ratio.map({0.8: 0.5, 1.0: 1.0, 1.5: 1.5}))\n",
    "#     [lambda x: x.g == 250]\n",
    "#     [lambda x: (\n",
    "# #         (x.mu == 5)\n",
    "# #         (x.fit_seed == 0)\n",
    "#         (x.fit_type.isin([\n",
    "#             'sfinder',\n",
    "#             'sfacts1_cpu',\n",
    "#             'sfacts1_gpu',\n",
    "# #             'sfacts2',\n",
    "# #             'sfacts3',\n",
    "#         ]))\n",
    "#     )]\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ], as_index=False)\n",
    "#     .agg(['mean', 'min', 'max', 'std', 'count', 'median'])\n",
    "#     .reset_index()\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'g',\n",
    "#         'n',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "# #         'sim_seed',\n",
    "# #         'fit_seed',\n",
    "#     ])\n",
    "#     .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "d0['jitter'] = np.random.random(d0.shape[0]) * 2 - 1\n",
    "\n",
    "g = 250\n",
    "s = 40\n",
    "\n",
    "\n",
    "fit_type_list = list(palette.keys())\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==s) & (x.fit_type.isin(fit_type_list)) & (x.g == g)]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", 'Unifrac Distance', 'mean distance', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "#     (\"braycurtis_trans_error\", \"Pairwise Bray-Curtis\", 'mean absolute error', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "    (\"community_entropy_error\", 'Compositional Entropy', 'mean absolute error', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", 'Best Match to True Genotype', 'weighted mean distance', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "    (\"rev_discrete_genotype_error\", 'Best Match to Inferred Genotype', 'weighted mean distance', dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-5, top=2e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "ncol = 2\n",
    "nrow = int(np.ceil(len(metric_list) / ncol))\n",
    "\n",
    "fig, axs = plt.subplots(nrow, ncol, figsize=(3.6 * ncol, 4 * nrow), sharex=True)\n",
    "\n",
    "for panel_letter, (met, title, axis_label, scale_kws, ylim_kws), ax in zip([\"A\", \"B\", \"C\", \"D\", \"E\"], metric_list, axs.flatten()):\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(axis_label)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "#     ax.set_yscale('symlog', linthresh=1e-5)\n",
    "    ax.set_xticks([0.5, 1, 1.5])\n",
    "    ax.set_xticklabels(['0.8x', '1.0x', '1.5x'])\n",
    "#     ax.set_xlim(0.85, 1.65)\n",
    "    ax.set_xlabel('strains')\n",
    "    ax.annotate(panel_letter, xy=(-0.1, 1.05), xycoords='axes fraction', fontsize=14, fontweight='bold')\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "#         d3 = d2.drop(idxwhere(d2.fit_type == 'mixtureS'))\n",
    "#         mwu = lib.stats.mannwhitneyu('fit_type', met, data=d3.sort_values(['sim_seed', 'fit_seed']))\n",
    "#         print(met, fit_s_ratio, mwu, )\n",
    "#         ax.annotate(\n",
    "#             pvalue_to_significance_marker(mwu[1]),\n",
    "#             xy=(\n",
    "#                 d2['xpos'].values[0],\n",
    "#                 1.5\n",
    "#             ), ha='center', va='top', fontsize=13)\n",
    "        for fit_type, offset in zip(fit_type_list, np.linspace(-1, 1, num=len(fit_type_list))):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)]#.sort_values((met, 'min'))\n",
    "            print(d3[met].median())\n",
    "#             print(fit_s_ratio, fit_type, d3.shape)\n",
    "            if d3.empty:\n",
    "                continue\n",
    "            ax.scatter(d3['xpos'] + d3['jitter'] * 0.04 + offset * 0.15, d3[met], edgecolor='lightgrey', color=palette[fit_type], alpha=0.7)\n",
    "\n",
    "# axs[-1, -1].axis('off')\n",
    "\n",
    "    \n",
    "fig.tight_layout(w_pad=2., h_pad=3.)\n",
    "fig.savefig('fig/accuracy_benchmarking_with_mixtureS.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.0, 1.0))\n",
    "for fit_type, fit_name in [('sfacts44_cpu', 'StrainFacts'), ('sfinder', 'Strain Finder'), ('mixtureS', 'MixtureS')]:\n",
    "    ax.scatter([], [], edgecolor='lightgrey', color=palette[fit_type], label=fit_name, s=100)\n",
    "ax.legend(loc='upper left')\n",
    "ax.axis('off')\n",
    "fig.savefig('fig/accuracy_benchmarking_with_mixtureS_legend.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Aggregate simulation results by finding the mean/min/std of each fit_seed\n",
    "# and then taking the mean of each of these values over the sim_seed.\n",
    "# I could then plot each runtime value as the mean\n",
    "\n",
    "\n",
    "palette = {\n",
    "# 'sfinder', 'sfacts1_cpu', 'sfacts1_gpu', 'sfacts2', 'sfacts3'\n",
    "    'sfacts41_cpu': 'blue',\n",
    "#     'sfacts41_gpu': 'purple',\n",
    "    'sfacts44_big': 'peachpuff',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "d0 = (\n",
    "    benchmarks2\n",
    "    .groupby([\n",
    "        's',\n",
    "        'fit_type',\n",
    "        'sim_seed',\n",
    "        'fit_s_ratio',\n",
    "    ])\n",
    "    .agg(['mean', 'min', 'std', 'count'])\n",
    "    .reset_index()\n",
    "#     .groupby([\n",
    "#         's',\n",
    "#         'fit_type',\n",
    "#         'fit_s_ratio',\n",
    "#     ])\n",
    "#     .agg(['mean', 'count'])\n",
    ")\n",
    "\n",
    "d1 = d0.reset_index()[lambda x: (x.s==80) & (x.fit_type.isin(fit_type_list))]\n",
    "metric_list = [\n",
    "#     (\"metagenotype_prediction_error\", dict(value='symlog', linthresh=1e-2, linscale=0.1), dict(bottom=-1e-3, top=1e0)),\n",
    "    (\"braycurtis_trans_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"unifrac_trans_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"unifrac_cis_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rank_abundance_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"fwd_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"rev_genotype_error\", dict(value='symlog', linthresh=1e-3, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"fwd_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "    (\"rev_discrete_genotype_error\", dict(value='symlog', linthresh=1e-4, linscale=0.1), dict(bottom=-1e-4, top=1e0)),\n",
    "#     (\"runtime\", dict(value='log'), dict(bottom=1e1, top=1e6)),\n",
    "          ]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(metric_list), figsize=(2 * len(metric_list), 4))\n",
    "\n",
    "for (met, scale_kws, ylim_kws), ax in zip(metric_list, axs):\n",
    "    ax.set_ylabel(met)\n",
    "    ax.set_yscale(**scale_kws)\n",
    "    ax.set_ylim(**ylim_kws)\n",
    "    ax.set_xticks([1, 1.5])\n",
    "    ax.set_xticklabels(['exact', 'over'])\n",
    "#     ax.set_ylim(1e-5)\n",
    "    for fit_s_ratio, d2 in d1.groupby(['fit_s_ratio']):\n",
    "        for fit_type, offset in zip(['sfacts41_cpu', 'sfinder', 'sfacts44_big'], [-0.1, 0, 0.1]):\n",
    "            d3 = d2[lambda x: (x.fit_type == fit_type)]\n",
    "#             print(fit_s_ratio, fit_type, d3.shape)\n",
    "            if d3.empty:\n",
    "                continue\n",
    "            ax.scatter([fit_s_ratio + offset] * d3.shape[0], d3[(met, 'min')], edgecolor='white', color=palette[fit_type])\n",
    "#             ax.scatter([fit_s_ratio + offset], d3[(met, 'mean', 'mean')], color=palette[fit_type])\n",
    "#             ax.vlines([fit_s_ratio + offset], d3[(met, 'min', 'mean')], d3[(met, 'mean', 'mean')], color=palette[fit_type])\n",
    "#             ax.vlines([fit_s_ratio + offset], d3[(met, 'mean', 'mean')] - d3[(met, 'std', 'mean')], d3[(met, 'mean', 'mean')] + d3[(met, 'std', 'mean')], color=palette[fit_type])\n",
    "    \n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot([40, 200, 1000], [432, 476, 716], label=250, lw=1.5, color='blue')\n",
    "plt.plot([40, 200, 1000], [492, 674, 1740], label=2500, lw=3, color='darkblue')\n",
    "plt.legend(title='g')\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.ylabel('Maximum GPU Memory Allocated (Mb)')\n",
    "plt.xlabel('nstrains (nsamples=strains * 2.5)')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(eval_path) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_benchmarks = []\n",
    "for n, g, s, sim_seed, fit_seed in tqdm(list(product(\n",
    "    [100, 200, 500, 1000, 2500, 10000],\n",
    "    [250, 500, 1000],\n",
    "    [20, 40, 100, 200, 400],\n",
    "    range(5),\n",
    "    range(5),\n",
    "))):\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n{n}-g{g}-s{s}-pi40-mu100-eps10-seed{sim_seed}\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    eval_path = f\"{mgen_prefix}.fit-sfacts44_gpumem-s{s}-seed{fit_seed}.gpumem\"\n",
    "#     print(eval_path)\n",
    "    try:\n",
    "        with open(eval_path) as f:\n",
    "            max_vmem = max([int(line) for i, line in enumerate(f)])\n",
    "    except FileNotFoundError:\n",
    "#         print(f\"Not found: {eval_path}\")\n",
    "        pass\n",
    "    else:\n",
    "        meta_dict = dict(\n",
    "            path=eval_path, n=n, s=s, g=g, sim_seed=sim_seed, fit_seed=fit_seed, max_vmem=max_vmem,\n",
    "        )\n",
    "        _benchmarks.append(meta_dict)\n",
    "_benchmarks = pd.DataFrame(_benchmarks).set_index('path')\n",
    "print(_benchmarks.shape)\n",
    "benchmarks3 = _benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = benchmarks3.groupby(['n', 'g', 's']).max_vmem.median().reset_index().assign(n_to_s_ratio=lambda x: x.n / x.s)\n",
    "ordered_s_list = [20, 40, 100, 200, 400]\n",
    "palette = {s: v for s, v in zip(ordered_s_list, mpl.cm.cool(ordered_s_list))}\n",
    "ls_map = {250: ':', 500: '--', 1000: '-'}\n",
    "\n",
    "for (g, s), d1 in d0.groupby(['g', 's']):\n",
    "    plt.plot('n', 'max_vmem', ls=ls_map[g], c=palette[s], data=d1.sort_values('n'), label='__nolegend__')\n",
    "    \n",
    "for s in ordered_s_list:\n",
    "    plt.plot([], [], ls='-', c=palette[s], label=f's={s}')\n",
    "for g in d0.g.unique():\n",
    "    plt.plot([], [], ls=ls_map[g], c='black', label=f'g={g}')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Peak GPU Memory Allocation (Mb)')\n",
    "plt.xlabel('samples')\n",
    "# plt.ylim(4e2, 5e3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d0 = benchmarks3.assign(n_to_s_ratio=lambda x: x.n / x.s)\n",
    "palette = {\n",
    "    'sfacts40': 'blue',\n",
    "    'sfinder': 'green',\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "for (g, d1), ax in zip(d0.groupby('g'), axs):\n",
    "    ax.set_title(f'g={g}')\n",
    "    for n_to_s_ratio, ls in zip([5, 2.5], ['-', '--']):\n",
    "        d2 = d1[d1.n_to_s_ratio == n_to_s_ratio]\n",
    "        ax.plot('n', 'max_vmem', ls=ls, c=palette['sfacts40'], data=d2, label='__nolegend__')\n",
    "        \n",
    "        \n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "for n_to_s_ratio, ls, ratio in zip([5, 2.5], ['-', '--'], [0.2, 0.4]):\n",
    "    ax.plot([], [], c='black', ls=ls, label=f'strains = samples * {ratio}')\n",
    "plt.legend()\n",
    "    \n",
    "    \n",
    "\n",
    "# for (s, g), d1 in d0.sort_values('n').groupby(['s', 'g']):\n",
    "#     plt.plot('n', 'max_vmem', ls=ls_map[g], c=palette[s], data=d1, label='__nolegend__')\n",
    "    \n",
    "# for s in ordered_s_list:\n",
    "#     plt.plot([], [], ls='-', c=palette[s], label=f's={s}')\n",
    "# for g in d0.g.unique():\n",
    "#     plt.plot([], [], ls=ls_map[g], c='black', label=f'g={g}')\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# plt.ylabel('Peak GPU Memory Allocation (Mb)')\n",
    "# plt.xlabel('samples')\n",
    "# # plt.ylim(4e2, 5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/sfacts_simulate-model_simplest_simulation-n100-g500-s400-pi40-mu100-eps10-seed0.metagenotype-n100-g500.fit-sfacts44_timeit-s400-g1000000-seed2.world.nc\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "_benchmarks = []\n",
    "for n, g, s, fit_seed, sim_seed, fit_type in tqdm(list(product(\n",
    "    [100, 200, 500, 1000, 2500, 10000],\n",
    "    [250, 500, 1000],\n",
    "    [20, 40, 100, 200, 400],\n",
    "    range(3),\n",
    "    range(3),\n",
    "    ['sfacts44', 'sfinder']\n",
    "))):\n",
    "    sim_prefix = f\"data/sfacts_simulate-model_simplest_simulation-n{n}-g{g}-s{s}-pi40-mu100-eps10-seed{sim_seed}\"\n",
    "    mgen_prefix = f\"{sim_prefix}.metagenotype-n{n}-g{g}\"\n",
    "    eval_path = f\"{mgen_prefix}.fit-{fit_type}_timeit-s{s}-seed{fit_seed}.time\"\n",
    "#     print(eval_path)\n",
    "    try:\n",
    "        with open(eval_path) as f:\n",
    "            d = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "#         print(eval_path)\n",
    "        continue\n",
    "    else:\n",
    "        if len(d) == 0:\n",
    "#             print(eval_path)\n",
    "            continue\n",
    "        maxrss = int(re.match('.* ([0-9]+)maxresident\\)k', d[0])[1])\n",
    "    meta_dict = dict(\n",
    "        path=eval_path,\n",
    "        n=n,\n",
    "        g=g,\n",
    "        s=s,\n",
    "        fit_seed=fit_seed,\n",
    "        sim_seed=sim_seed,\n",
    "        fit_type=fit_type,\n",
    "        maxrss=maxrss,\n",
    "    )\n",
    "    _benchmarks.append(meta_dict)\n",
    "_benchmarks = pd.DataFrame(_benchmarks).set_index('path')\n",
    "print(_benchmarks.shape)\n",
    "benchmarks4 = _benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks4[lambda x: x.fit_type=='sfacts44'].groupby(['n', 'g', 's']).maxrss.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks4.groupby(['n', 'g', 's', 'fit_type']).apply(len).xs('sfacts44', level='fit_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks4['s'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "d0 = (\n",
    "    benchmarks4\n",
    "    .drop(benchmarks4[lambda x: (x.n == 10000) & (x.g==1000)].index)  # These must have gotten swapped.\n",
    "    .groupby(['n', 'g', 's', 'fit_type', 'sim_seed', 'fit_seed'])\n",
    "    .maxrss\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        n_to_s_ratio=lambda x: x.n / x.s,\n",
    "        maxrss_mb=lambda x: x.maxrss / 1e3\n",
    "    )\n",
    ")\n",
    "\n",
    "fit = smf.ols('maxrss ~ n:g + n:s + g:s', data=d0[lambda x: (x.fit_type=='sfacts44')]).fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0[lambda x: (x.fit_type=='sfacts44')].groupby(['n', 'g', 's']).apply(len).reset_index().s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks4.drop(benchmarks4[lambda x: (x.n == 10000) & (x.g==1000)].index)[lambda x: (x.fit_type=='sfacts44')].groupby(['n', 'g', 's']).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "d0 = (\n",
    "    benchmarks4\n",
    "    .drop(benchmarks4[lambda x: (x.n == 10000) & (x.g==1000)].index)  # These must have gotten swapped.\n",
    "    .groupby(['n', 'g', 's', 'fit_type', 'sim_seed', 'fit_seed'])\n",
    "    .maxrss\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        n_to_s_ratio=lambda x: x.n / x.s,\n",
    "        maxrss_mb=lambda x: x.maxrss / 1e3\n",
    "    )\n",
    ")\n",
    "\n",
    "fit2 = smf.rlm('maxrss ~ n:g + n:s + g:s', data=d0[lambda x: (x.fit_type=='sfacts44')]).fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0_extrapolate = pd.DataFrame(dict(g=1000, s=400, n=np.logspace(np.log10(100), np.log10(50_000))))\n",
    "d0_extrapolate['predict_mb'] = fit2.predict(d0_extrapolate) / 1_000\n",
    "\n",
    "d0_extrapolate[d0_extrapolate.predict_mb < 32_000].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    benchmarks4\n",
    "    .drop(benchmarks4[lambda x: (x.n == 10000) & (x.g==1000)].index)  # These must have gotten swapped.\n",
    "    .groupby(['n', 'g', 's', 'fit_type'])\n",
    "    .maxrss\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        n_to_s_ratio=lambda x: x.n / x.s,\n",
    "        maxrss_mb=lambda x: x.maxrss / 1e3\n",
    "    )\n",
    ")\n",
    "ordered_s_list = [20, 40, 100, 200, 400]\n",
    "\n",
    "ls_map = {250: ':', 500: '--', 1000: '-'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for fit_type, cm in zip(['sfacts44'], [mpl.cm.Blues]):\n",
    "    palette = {s: v for s, v in zip(ordered_s_list, cm(ordered_s_list))}\n",
    "    for (s, g), d1 in d0[d0.fit_type == fit_type].sort_values('n').groupby(['s', 'g']):\n",
    "        ax.plot('n', 'maxrss_mb', ls=ls_map[g], c=palette[s], data=d1, lw=2, label='__nolegend__')\n",
    "    for s in d0.s.sort_values().unique():\n",
    "        ax.plot([], [], ls='-', c=palette[s], label=f's={s}')\n",
    "\n",
    "\n",
    "for g in [250, 500, 1000]:\n",
    "    plt.plot([], [], ls=ls_map[g], color='grey', label=f'g={g}')\n",
    "\n",
    "plt.plot('n', 'predict_mb', data=d0_extrapolate, lw=1, color='red', ls='dashdot', label='predicted')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper left', ncol=1)\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "ax.set_xlim(0, 1.2e4)\n",
    "ax.set_ylim(0, 1.0e4)\n",
    "ax.set_ylabel('Peak Memory Allocation (Mb)')\n",
    "ax.set_xlabel('samples')\n",
    "# ax.set_ylim(5e1, 1e4)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrapolate2 = pd.DataFrame(dict(g=1000, s=100, n=np.logspace(np.log10(100), np.log10(50_000))))\n",
    "extrapolate2['predict_mb'] = fit.predict(extrapolate2) / 1_000\n",
    "\n",
    "extrapolate2[extrapolate2.predict_mb < 32_000].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrapolate3 = pd.DataFrame(dict(g=1000, s=100, n=np.logspace(np.log10(100), np.log10(50_000))))\n",
    "extrapolate3['predict_mb'] = fit2.predict(extrapolate2) / 1_000\n",
    "\n",
    "extrapolate3[extrapolate3.predict_mb < 32_000].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    benchmarks4\n",
    "    [lambda x: x.s == 100]\n",
    "    [lambda x: ~((x.n == 10000) & (x.g==1000))]  # These must have gotten RAM swapped.\n",
    "    .groupby(['n', 'g', 's', 'fit_type'])\n",
    "    .maxrss\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        n_to_s_ratio=lambda x: x.n / x.s,\n",
    "        maxrss_mb=lambda x: x.maxrss / 1e3\n",
    "    )\n",
    ")\n",
    "ordered_g_list = [250, 500, 1000]\n",
    "\n",
    "ls_map = {250: ':', 500: '--', 1000: '-'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for fit_type, cm in zip(['sfacts44'], [mpl.cm.Blues]):\n",
    "    palette = {s: v for s, v in zip([None] + ordered_g_list, cm(np.linspace(0, 1, num=len(ordered_g_list) + 1)))}\n",
    "    for g, d1 in d0[d0.fit_type == fit_type].sort_values(['n', 'g']).groupby(['g']):\n",
    "        ax.plot('n', 'maxrss_mb', marker='.', c=palette[g], markersize=12, data=d1, lw=1, ls='-', label=f'G={g}')\n",
    "#     for s in d0.s.sort_values().unique():\n",
    "#         ax.plot([], [], ls='-', c=palette[g], label=f'g={g}')\n",
    "\n",
    "\n",
    "# for g in [250, 500, 1000]:\n",
    "#     plt.plot([], [], ls=ls_map[g], color='grey', label=f'g={g}')\n",
    "\n",
    "plt.plot('n', 'predict_mb', data=extrapolate2, color='red', lw=2, ls='-', label='predicted', alpha=0.7)\n",
    "\n",
    "\n",
    "ax.legend(loc='upper left', ncol=1)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('peak memory allocation (Mb)')\n",
    "ax.set_xlabel('samples (N)')\n",
    "# ax.set_ylim(5e1, 1e4)\n",
    "# fig.tight_layout()\n",
    "\n",
    "fig.savefig('fig/memory_profiling.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d0 = (\n",
    "    benchmarks4\n",
    "    [lambda x: x.s == 100]\n",
    "    [lambda x: ~((x.n == 10000) & (x.g==1000))]  # These must have gotten RAM swapped.\n",
    "    .groupby(['n', 'g', 's', 'fit_type'])\n",
    "    .maxrss\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        n_to_s_ratio=lambda x: x.n / x.s,\n",
    "        maxrss_mb=lambda x: x.maxrss / 1e3\n",
    "    )\n",
    ")\n",
    "ordered_g_list = [250, 500, 1000]\n",
    "\n",
    "ls_map = {250: ':', 500: '--', 1000: '-'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for fit_type, cm in zip(['sfacts44'], [mpl.cm.Blues]):\n",
    "    palette = {s: v for s, v in zip([None] + ordered_g_list, cm(np.linspace(0, 1, num=len(ordered_g_list) + 1)))}\n",
    "    for g, d1 in d0[d0.fit_type == fit_type].sort_values(['n', 'g']).groupby(['g']):\n",
    "        ax.plot('n', 'maxrss_mb', ls='-', marker='.', c=palette[g], data=d1, lw=1, label=f'G={g}')\n",
    "#     for s in d0.s.sort_values().unique():\n",
    "#         ax.plot([], [], ls='-', c=palette[g], label=f'g={g}')\n",
    "\n",
    "\n",
    "# for g in [250, 500, 1000]:\n",
    "#     plt.plot([], [], ls=ls_map[g], color='grey', label=f'g={g}')\n",
    "\n",
    "plt.plot('n', 'predict_mb', data=extrapolate3, lw=2, color='red', ls='-', label='predicted', alpha=0.7)\n",
    "\n",
    "\n",
    "ax.legend(loc='upper left', ncol=1)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('peak memory allocation (Mb)')\n",
    "ax.set_xlabel('samples (N)')\n",
    "# ax.set_ylim(5e1, 1e4)\n",
    "# fig.tight_layout()\n",
    "\n",
    "fig.savefig('fig/memory_profiling2.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    benchmarks4\n",
    "    .drop(benchmarks4[lambda x: (x.n == 10000) & (x.g==1000)].index)  # These must have gotten swapped.\n",
    "    .groupby(['n', 'g', 's', 'fit_type'])\n",
    "    .maxrss\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        n_to_s_ratio=lambda x: x.n / x.s,\n",
    "        maxrss_mb=lambda x: x.maxrss / 1e3\n",
    "    )\n",
    ")\n",
    "ordered_s_list = [20, 40, 100, 200, 400]\n",
    "\n",
    "ls_map = {250: ':', 500: '--', 1000: '-'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for fit_type, cm in zip(['sfacts44'], [mpl.cm.Blues]):\n",
    "    palette = {s: v for s, v in zip(ordered_s_list, cm(ordered_s_list))}\n",
    "    for (s, g), d1 in d0[d0.fit_type == fit_type].sort_values('n').groupby(['s', 'g']):\n",
    "        ax.plot('n', 'maxrss_mb', ls=ls_map[g], c=palette[s], data=d1, lw=2, label='__nolegend__')\n",
    "    for s in d0.s.sort_values().unique():\n",
    "        ax.plot([], [], ls='-', c=palette[s], label=f'S={s}')\n",
    "\n",
    "\n",
    "for g in [250, 500, 1000]:\n",
    "    plt.plot([], [], ls=ls_map[g], color='grey', label=f'G={g}')\n",
    "\n",
    "plt.plot('n', 'predict_mb', data=d0_extrapolate, lw=1, color='red', ls='dashdot', label='predicted')\n",
    "\n",
    "\n",
    "ax.legend(loc='upper left', ncol=1)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Peak Memory Allocation (Mb)')\n",
    "ax.set_xlabel('samples (N)')\n",
    "# ax.set_ylim(5e1, 1e4)\n",
    "# fig.tight_layout()\n",
    "\n",
    "fig.savefig('doc/static/memory_profiling_more_strains_figure.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}