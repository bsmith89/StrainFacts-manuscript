{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../haplo-benchmark/include/StrainFacts/sfacts/model_zoo/simple_ssdd2_with_error.py\n",
    "# import sfacts as sf\n",
    "from sfacts.model_zoo.components import (\n",
    "    _mapping_subset,\n",
    "    powerperturb_transformation_unit_interval,\n",
    "    powerperturb_transformation,\n",
    "    SHARED_DESCRIPTIONS,\n",
    "    SHARED_DIMS,\n",
    ")\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "\n",
    "@sf.model.structure(\n",
    "    dims=SHARED_DIMS,\n",
    "    description=_mapping_subset(\n",
    "        SHARED_DESCRIPTIONS,\n",
    "        [\n",
    "            \"rho\",\n",
    "            \"p\",\n",
    "            \"m\",\n",
    "            \"y\",\n",
    "            \"epsilon\",\n",
    "            \"alpha\",\n",
    "            \"genotypes\",\n",
    "            \"communities\",\n",
    "            \"metagenotypes\",\n",
    "            \"mu\",\n",
    "        ],\n",
    "    ),\n",
    "    default_hyperparameters=dict(\n",
    "        gamma_hyper=0.01,\n",
    "        rho_hyper=5.0,\n",
    "        pi_hyper=0.2,\n",
    "        m_hyper_concentration=0.01,\n",
    "        m_hyper_mean=2,\n",
    "        epsilon_hyper_mode=0.01,\n",
    "        epsilon_hyper_spread=1.5,\n",
    "        alpha_hyper_mean=200,\n",
    "        alpha_hyper_scale=1,\n",
    "        eps=1e-20,\n",
    "        # alpha=1e3,\n",
    "    ),\n",
    ")\n",
    "def model0(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    a,\n",
    "    gamma_hyper,\n",
    "    rho_hyper,\n",
    "    pi_hyper,\n",
    "    m_hyper_concentration,\n",
    "    m_hyper_mean,\n",
    "    epsilon_hyper_mode,\n",
    "    epsilon_hyper_spread,\n",
    "    alpha_hyper_mean,\n",
    "    alpha_hyper_scale,\n",
    "    eps,\n",
    "    _unit,\n",
    "):\n",
    "    with pyro.plate(\"position\", g, dim=-1):\n",
    "        with pyro.plate(\"strain\", s, dim=-2):\n",
    "            _gamma = pyro.sample(\"_gamma\", dist.Beta(_unit, _unit))\n",
    "            gamma = pyro.deterministic(\n",
    "                \"gamma\",\n",
    "                powerperturb_transformation_unit_interval(\n",
    "                    _gamma, 1 / gamma_hyper, _unit\n",
    "                ),\n",
    "            )\n",
    "    pyro.deterministic(\"genotypes\", gamma)\n",
    "\n",
    "    # Meta-community composition\n",
    "    _rho = pyro.sample(\"_rho\", dist.Dirichlet(_unit.repeat(s)))\n",
    "    rho = pyro.deterministic(\n",
    "        \"rho\", powerperturb_transformation(_rho, 1 / rho_hyper, _unit)\n",
    "    )\n",
    "    # rho = pyro.deterministic(\"rho\", (_rho_unconditioned + eps) / (1 + eps * s))\n",
    "    pyro.deterministic(\"metacommunity\", rho)\n",
    "\n",
    "    with pyro.plate(\"sample\", n, dim=-1):\n",
    "        # Community composition\n",
    "        _pi = pyro.sample(\"_pi\", dist.Dirichlet(_unit.repeat(s)))\n",
    "        pi = pyro.deterministic(\n",
    "            \"pi\",\n",
    "            powerperturb_transformation(_pi, 1 / pi_hyper, rho),\n",
    "        )\n",
    "        epsilon = pyro.sample(\n",
    "            \"epsilon\",\n",
    "            dist.Beta(epsilon_hyper_spread, epsilon_hyper_spread / epsilon_hyper_mode),\n",
    "        ).unsqueeze(-1)\n",
    "        alpha = pyro.sample(\n",
    "            \"alpha\",\n",
    "            dist.LogNormal(loc=torch.log(alpha_hyper_mean), scale=alpha_hyper_scale),\n",
    "        ).unsqueeze(-1)\n",
    "    pyro.deterministic(\"communities\", pi)\n",
    "\n",
    "    m = pyro.sample(\n",
    "        \"m\",\n",
    "        dist.GammaPoisson(concentration=m_hyper_concentration, rate=m_hyper_concentration / m_hyper_mean)\n",
    "        .expand([n, g])\n",
    "        .to_event(),\n",
    "    )\n",
    "\n",
    "    # Expected fractions of each allele at each position\n",
    "    p_noerr = pyro.deterministic(\"p_noerr\", pi @ gamma)\n",
    "    p = pyro.deterministic(\n",
    "        \"p\", (1 - epsilon / 2) * (p_noerr) + (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "    # Observation\n",
    "    y = pyro.sample(\n",
    "        \"y\",\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m,\n",
    "        ).to_event(),\n",
    "    )\n",
    "    pyro.deterministic(\"metagenotypes\", torch.stack([y, m - y], dim=-1))\n",
    "    pyro.deterministic(\"mu\", m.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions import TorchDistribution\n",
    "from torch.distributions import constraints\n",
    "import torch\n",
    "\n",
    "\n",
    "def ssd_loglik(alpha, p, a, x):\n",
    "    D = x.shape[-1]\n",
    "    sum_alpha = torch.sum(alpha, dim=-1, keepdim=True)\n",
    "    termA = torch.lgamma(sum_alpha) - torch.sum(torch.lgamma(alpha), dim=-1, keepdim=True)\n",
    "    termB = -(D - 1) * torch.log(a)\n",
    "    termC_num = torch.sum((-(alpha / a) * torch.log(p)) + (alpha / a - 1) * torch.log(x), dim=-1, keepdim=True)\n",
    "    termC_den = sum_alpha * torch.log(torch.sum((x / p) ** (1 / a),  dim=-1, keepdim=True))\n",
    "#     print('a', termA)\n",
    "#     print('b', termB)\n",
    "#     print('num', termC_num)\n",
    "#     print('den', termC_den)\n",
    "    return termA + termB + termC_num - termC_den\n",
    "\n",
    "class ShiftedScaledDirichlet(TorchDistribution):\n",
    "    support = pyro.distributions.Dirichlet.support\n",
    "    has_rsample = False\n",
    "    arg_constraints = {\n",
    "        'alpha': constraints.positive,\n",
    "        'p': constraints.unit_interval,\n",
    "        'a': constraints.positive,\n",
    "    }\n",
    "\n",
    "    def __init__(self, alpha, p, a, validate_args=None):\n",
    "        alpha, p, a = torch.distributions.utils.broadcast_all(\n",
    "            alpha, p, a.unsqueeze(dim=-1)\n",
    "        )\n",
    "        a = a[..., [0]]\n",
    "#         print(alpha, p, a)\n",
    "        \n",
    "#         batch_shape = alpha.shape[:-1]\n",
    "#         event_shape = alpha.shape[-1:]\n",
    "        self._dirichlet = pyro.distributions.Dirichlet(\n",
    "            concentration=alpha\n",
    "        )\n",
    "        self.p = p\n",
    "        self.a = a\n",
    "        super(TorchDistribution, self).__init__(\n",
    "            self._dirichlet.batch_shape,\n",
    "            self._dirichlet.event_shape,\n",
    "            validate_args=validate_args\n",
    "        )\n",
    "        \n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return self._dirichlet.concentration\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        y = self._dirichlet.sample(sample_shape)\n",
    "        return sf.model_zoo.components.powerperturb_transformation(y, self.a, self.p)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        return ssd_loglik(self.alpha, self.p, self.a, value).squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 3\n",
    "d = ShiftedScaledDirichlet(torch.tensor([0.2, 0.3, 0.5]), torch.tensor([1.]*3) / s, torch.tensor([[5.0], [1.0], [0.1], [0.2]]))\n",
    "x = d.sample()\n",
    "\n",
    "print(x)\n",
    "print()\n",
    "d.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../haplo-benchmark/include/StrainFacts/sfacts/model_zoo/simple_ssdd2_with_error.py\n",
    "# import sfacts as sf\n",
    "from sfacts.model_zoo.components import (\n",
    "    _mapping_subset,\n",
    "    powerperturb_transformation_unit_interval,\n",
    "    powerperturb_transformation,\n",
    "    SHARED_DESCRIPTIONS,\n",
    "    SHARED_DIMS,\n",
    ")\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "\n",
    "@sf.model.structure(\n",
    "    dims=SHARED_DIMS,\n",
    "    description=_mapping_subset(\n",
    "        SHARED_DESCRIPTIONS,\n",
    "        [\n",
    "            \"rho\",\n",
    "            \"p\",\n",
    "            \"m\",\n",
    "            \"y\",\n",
    "            \"epsilon\",\n",
    "            \"alpha\",\n",
    "            \"genotypes\",\n",
    "            \"communities\",\n",
    "            \"metagenotypes\",\n",
    "            \"mu\",\n",
    "        ],\n",
    "    ),\n",
    "    default_hyperparameters=dict(\n",
    "        gamma_hyper=0.01,\n",
    "        rho_hyper=5.0,\n",
    "        pi_hyper=0.2,\n",
    "        m_hyper_concentration=0.01,\n",
    "        m_hyper_mean=2,\n",
    "        epsilon_hyper_mode=0.01,\n",
    "        epsilon_hyper_spread=1.5,\n",
    "        alpha_hyper_mean=200,\n",
    "        alpha_hyper_scale=1,\n",
    "        eps=1e-20,\n",
    "        # alpha=1e3,\n",
    "    ),\n",
    ")\n",
    "def model1(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    a,\n",
    "    gamma_hyper,\n",
    "    rho_hyper,\n",
    "    pi_hyper,\n",
    "    m_hyper_concentration,\n",
    "    m_hyper_mean,\n",
    "    epsilon_hyper_mode,\n",
    "    epsilon_hyper_spread,\n",
    "    alpha_hyper_mean,\n",
    "    alpha_hyper_scale,\n",
    "    eps,\n",
    "    _unit,\n",
    "):\n",
    "    with pyro.plate(\"position\", g, dim=-1):\n",
    "        with pyro.plate(\"strain\", s, dim=-2):\n",
    "#             _gamma = pyro.sample(\"_gamma\", dist.Beta(_unit, _unit))\n",
    "#             gamma = pyro.deterministic(\n",
    "#                 \"gamma\",\n",
    "#                 powerperturb_transformation_unit_interval(\n",
    "#                     _gamma, 1 / gamma_hyper, _unit\n",
    "#                 ),\n",
    "#             )\n",
    "            _gamma = pyro.sample(\"_gamma\", ShiftedScaledDirichlet(_unit.repeat(a), _unit.repeat(a) / a, 1 / gamma_hyper))\n",
    "            gamma = _gamma[...,0]\n",
    "#             gamma = pyro.sample(\"gamma\", ShiftedScaledBeta(concentration1=_unit, concentration0=_unit, p=_unit * 0.5, a=1 / gamma_hyper))\n",
    "    pyro.deterministic(\"genotypes\", gamma)\n",
    "\n",
    "\n",
    "    # Meta-community composition\n",
    "    rho = pyro.sample(\"rho\", ShiftedScaledDirichlet(_unit.repeat(s), _unit.repeat(s) / s, 1 / rho_hyper))\n",
    "    pyro.deterministic(\"metacommunity\", rho)\n",
    "\n",
    "    with pyro.plate(\"sample\", n, dim=-1):\n",
    "        # Community composition\n",
    "        pi = pyro.sample(\"pi\", ShiftedScaledDirichlet(_unit.repeat(s), rho, 1 / pi_hyper))\n",
    "        epsilon = pyro.sample(\n",
    "            \"epsilon\",\n",
    "            dist.Beta(epsilon_hyper_spread, epsilon_hyper_spread / epsilon_hyper_mode),\n",
    "        ).unsqueeze(-1)\n",
    "        alpha = pyro.sample(\n",
    "            \"alpha\",\n",
    "            dist.LogNormal(loc=torch.log(alpha_hyper_mean), scale=alpha_hyper_scale),\n",
    "        ).unsqueeze(-1)\n",
    "    pyro.deterministic(\"communities\", pi)\n",
    "\n",
    "    m = pyro.sample(\n",
    "        \"m\",\n",
    "        dist.GammaPoisson(concentration=m_hyper_concentration, rate=m_hyper_concentration / m_hyper_mean)\n",
    "        .expand([n, g])\n",
    "        .to_event(),\n",
    "    )\n",
    "\n",
    "    # Expected fractions of each allele at each position\n",
    "    p_noerr = pyro.deterministic(\"p_noerr\", pi @ gamma)\n",
    "    p = pyro.deterministic(\n",
    "        \"p\", (1 - epsilon / 2) * (p_noerr) + (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "    # Observation\n",
    "    y = pyro.sample(\n",
    "        \"y\",\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m,\n",
    "        ).to_event(),\n",
    "    )\n",
    "    pyro.deterministic(\"metagenotypes\", torch.stack([y, m - y], dim=-1))\n",
    "    pyro.deterministic(\"mu\", m.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 500\n",
    "n = 50\n",
    "s = 10\n",
    "\n",
    "sim1 = sf.model.ParameterizedModel(\n",
    "    model1,\n",
    "    coords=dict(\n",
    "        sample=range(n),\n",
    "        position=range(g),\n",
    "        strain=range(s),\n",
    "        allele=['alt', 'ref'],\n",
    "    ),\n",
    "    hyperparameters=dict(\n",
    "        gamma_hyper=1e-5,\n",
    "        rho_hyper=1.0,\n",
    "        pi_hyper=0.1,\n",
    "#         m_hyper_concentration=1000.,\n",
    "# #         m_hyper_rate=m_hyper_concentration / m_hyper_mean # 100. / 200,\n",
    "#         m_hyper_mean=0.5,\n",
    "        epsilon_hyper_mode=0.01,\n",
    "        epsilon_hyper_spread=1.5,\n",
    "        alpha_hyper_mean=200,\n",
    "        alpha_hyper_scale=1,\n",
    "    ),\n",
    "    data=dict(\n",
    "        epsilon=np.ones(n) * 0.01,\n",
    "        alpha=np.ones(n) * 1e6,\n",
    "        m=np.ones((n, g)) * 1,\n",
    "    ),\n",
    ").simulate_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_metagenotype(sim1)\n",
    "sf.plot.plot_community(sim1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sim1.communities.max(\"strain\"))\n",
    "sf.plot.plot_genotype(sim1, row_colors_func=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%mprun -f sf.workflow.fit_metagenotypes_simple\n",
    "\n",
    "nposition = 50\n",
    "\n",
    "fit1, (history1, *_) = sf.workflow.fit_subsampled_metagenotypes_then_collapse_and_iteratively_refit_genotypes(\n",
    "    model1,\n",
    "    sim1.metagenotypes,\n",
    "    nposition=nposition,\n",
    "    nstrain=20,\n",
    "    hyperparameters=dict(\n",
    "        gamma_hyper=1e-7,\n",
    "#         rho_hyper=0.2,\n",
    "#         pi_hyper=0.15,\n",
    "    ),\n",
    "    stage2_hyperparameters=dict(gamma_hyper=1.0),\n",
    "    anneal_hyperparameters=dict(\n",
    "#         gamma_hyper=dict(name='log', start=1e-4, end=1e-7, wait_steps=1000),\n",
    "        rho_hyper=dict(name='log', start=1.0, end=0.2, wait_steps=1000),\n",
    "        pi_hyper=dict(name='log', start=1.0, end=0.4, wait_steps=1000),\n",
    "    ),\n",
    "    annealiter=2000,\n",
    "    estimation_kwargs=dict(\n",
    "        jit=True, catch_keyboard_interrupt=True, ignore_jit_warnings=True,\n",
    "    ),\n",
    "    diss_thresh=0.02,\n",
    "    frac_thresh=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%mprun -f sf.workflow.fit_metagenotypes_simple\n",
    "\n",
    "nposition = 100\n",
    "\n",
    "fit2, (history2, *_) = sf.workflow.fit_subsampled_metagenotypes_then_collapse_and_iteratively_refit_genotypes(\n",
    "    model1,\n",
    "    sim1.metagenotypes,\n",
    "    nposition=nposition,\n",
    "    nstrain=20,\n",
    "    hyperparameters=dict(\n",
    "        gamma_hyper=1e-7,\n",
    "#         rho_hyper=0.2,\n",
    "#         pi_hyper=0.15,\n",
    "    ),\n",
    "    stage2_hyperparameters=dict(gamma_hyper=1.0),\n",
    "    anneal_hyperparameters=dict(\n",
    "#         gamma_hyper=dict(name='log', start=1e-4, end=1e-7, wait_steps=1000),\n",
    "        rho_hyper=dict(name='log', start=1.0, end=0.2, wait_steps=1000),\n",
    "        pi_hyper=dict(name='log', start=1.0, end=0.4, wait_steps=1000),\n",
    "    ),\n",
    "    annealiter=2000,\n",
    "    estimation_kwargs=dict(\n",
    "        jit=True, catch_keyboard_interrupt=True, ignore_jit_warnings=True,\n",
    "    ),\n",
    "    diss_thresh=0.02,\n",
    "    frac_thresh=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%mprun -f sf.workflow.fit_metagenotypes_simple\n",
    "\n",
    "nposition = 200\n",
    "\n",
    "fit3, (history3, *_) = sf.workflow.fit_subsampled_metagenotypes_then_collapse_and_iteratively_refit_genotypes(\n",
    "    model1,\n",
    "    sim1.metagenotypes,\n",
    "    nposition=nposition,\n",
    "    nstrain=20,\n",
    "    hyperparameters=dict(\n",
    "        gamma_hyper=1e-7,\n",
    "#         rho_hyper=0.2,\n",
    "#         pi_hyper=0.15,\n",
    "    ),\n",
    "    stage2_hyperparameters=dict(gamma_hyper=1.0),\n",
    "    anneal_hyperparameters=dict(\n",
    "#         gamma_hyper=dict(name='log', start=1e-4, end=1e-7, wait_steps=1000),\n",
    "        rho_hyper=dict(name='log', start=1.0, end=0.2, wait_steps=1000),\n",
    "        pi_hyper=dict(name='log', start=1.0, end=0.4, wait_steps=1000),\n",
    "    ),\n",
    "    annealiter=2000,\n",
    "    estimation_kwargs=dict(\n",
    "        jit=True, catch_keyboard_interrupt=True, ignore_jit_warnings=True,\n",
    "    ),\n",
    "    diss_thresh=0.02,\n",
    "    frac_thresh=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%mprun -f sf.workflow.fit_metagenotypes_simple\n",
    "\n",
    "nposition = 500\n",
    "\n",
    "fit4, (history4, *_) = sf.workflow.fit_subsampled_metagenotypes_then_collapse_and_iteratively_refit_genotypes(\n",
    "    model1,\n",
    "    sim1.metagenotypes,\n",
    "    nposition=nposition,\n",
    "    nstrain=20,\n",
    "    hyperparameters=dict(\n",
    "        gamma_hyper=1e-7,\n",
    "#         rho_hyper=0.2,\n",
    "#         pi_hyper=0.15,\n",
    "    ),\n",
    "    stage2_hyperparameters=dict(gamma_hyper=1.0),\n",
    "    anneal_hyperparameters=dict(\n",
    "#         gamma_hyper=dict(name='log', start=1e-4, end=1e-7, wait_steps=1000),\n",
    "        rho_hyper=dict(name='log', start=1.0, end=0.2, wait_steps=1000),\n",
    "        pi_hyper=dict(name='log', start=1.0, end=0.4, wait_steps=1000),\n",
    "    ),\n",
    "    annealiter=2000,\n",
    "    estimation_kwargs=dict(\n",
    "        jit=True, catch_keyboard_interrupt=True, ignore_jit_warnings=True,\n",
    "    ),\n",
    "    diss_thresh=0.02,\n",
    "    frac_thresh=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sim1\n",
    "f = fit1\n",
    "\n",
    "\n",
    "sf.plot.plot_community(s, col_linkage_func=lambda w: s.metagenotypes.linkage(\"sample\"))\n",
    "\n",
    "for f in [fit1, fit2, fit3, fit4]:\n",
    "    print(\n",
    "        sf.evaluation.braycurtis_error(s, f)[0],\n",
    "        sf.evaluation.unifrac_error(s, f)[0],\n",
    "        sf.evaluation.unifrac_error2(s, f)[0],\n",
    "        sf.evaluation.genotype_error(s, f)[0],\n",
    "        sf.evaluation.discretized_genotype_error(s, f)[0],\n",
    "        sf.evaluation.genotype_error(f, s)[0],\n",
    "        sf.evaluation.discretized_genotype_error(f, s)[0],\n",
    "    )\n",
    "    sf.plot.plot_community(f, col_linkage_func=lambda w: s.metagenotypes.linkage(\"sample\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}